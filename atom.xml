<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[An Honglei ’s Blog]]></title>
  <link href="www.anhaoker.com/atom.xml" rel="self"/>
  <link href="www.anhaoker.com/"/>
  <updated>2018-07-06T17:39:57+08:00</updated>
  <id>www.anhaoker.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im">MWeb</generator>

  
  <entry>
    <title type="html"><![CDATA[LINUX 快捷键整理]]></title>
    <link href="www.anhaoker.com/15306935051951.html"/>
    <updated>2018-07-04T16:38:25+08:00</updated>
    <id>www.anhaoker.com/15306935051951.html</id>
    <content type="html"><![CDATA[
<p><img src="http://pb9nlfw6h.bkt.clouddn.com/15307636793821.jpg" alt=""/></p>

<ul>
<li>
<a href="#toc_0">快捷键</a>
<ul>
<li>
<a href="#toc_1">ctrl</a>
</li>
<li>
<a href="#toc_2">Alt</a>
</li>
<li>
<a href="#toc_3">ESC</a>
</li>
</ul>
</li>
<li>
<a href="#toc_4">功能分类</a>
<ul>
<li>
<a href="#toc_5">剪切板操作</a>
</li>
<li>
<a href="#toc_6">光标操作</a>
</li>
<li>
<a href="#toc_7">文本处理操作</a>
</li>
<li>
<a href="#toc_8">任务处理操作</a>
</li>
<li>
<a href="#toc_9">标签页处理操作</a>
</li>
<li>
<a href="#toc_10">窗口操作</a>
</li>
<li>
<a href="#toc_11">历史命令操作</a>
</li>
<li>
<a href="#toc_12">其他操作</a>
</li>
</ul>
</li>
<li>
<a href="#toc_13">参考：</a>
</li>
<li>
<a href="#toc_14">示例操作</a>
</li>
</ul>


<h2 id="toc_0">快捷键</h2>

<p><img src="http://pb9nlfw6h.bkt.clouddn.com/15307620204271.jpg" alt=""/></p>

<h3 id="toc_1">ctrl</h3>

<p>作为快捷键的基础，在linux系统的centos下，我们经常使用如下参数。</p>

<pre><code>a——光标回到命令行首。 （a：ahead）

b——光标向行首移动一个字符。 （b：backwards）

c——中断终端中正在执行的任务。

d——删除当前一个字符或从 shell 提示中注销（并关闭）就不必键入 exit 或 logout 。

e——光标回到命令行尾。 （e： end）

f——光标向行尾移动一个字符。 （f： forwards）

h——删除光标前一个字符，同backspace 键相同。

i——相当于Tab键。

k——删除光标处到行尾的字符。

l——清屏，相当于clear。

o/m——相当Enter键。

n——下一个使用的历史命令。（n： next ）

p——上一个使用的历史命令。 （p： previous）

r——快速检索历史命令。（r： retrieve）。

s——使终端发呆，静止，可以使快速输出的终端屏幕停下来。

q——退出Ctrl+s引起的发呆。

t——交换光标所在字符和其前的字符。

u——清除光标前至行首间的所有内容。

w——删除光标处到行首（以空格和标点为分隔）的字符。

x——同上但再按一次会从新回到原位置。

y——粘贴或者恢复上次的删除。

z——使正在运行在终端的任务，运行于后台。 （可用fg恢复）

[——相当于Esc键。

</code></pre>

<h3 id="toc_2">Alt</h3>

<p>多用于桌面环境和bash（shell环境中多数未开启）</p>

<pre><code>
b——光标往回（backward）移动到前一个单词

c——将光标所在字符到词尾改为首字母大写

u——将光标所在字符到词尾转化为大写

l——将光标所在字符到词尾转化为小写

r——撤销对从历史记录中带来的命令的修改。

F2——运行

F4——关闭当前窗口

F9——最小化当前窗口

F10——最大化当前窗口

n——n为1-9数字，快速切换标签页

Tab——切换窗口

按住左键——移动窗口（或在最下面的任务栏滚动鼠标滑轮）


</code></pre>

<p>** Meta被标记为ALT键(在我所使用的键盘上，尽管有ALT键，但其并不是作为Meta功能使用, Macbook上也没有单独的Meta键)，此时可以选用其中的一个ATL键通过设置作为Meta键。如果没有ALT键，可以通过先按ESC键，再按相应的字母键实现Meta组合件的功能。<br/>
但是实际上先按ESC，再按相应的组合键，前后要按两次以上，很不方便，通常都是通过修改设置，将ALT复用为Meta键。 **</p>

<h3 id="toc_3">ESC</h3>

<pre><code>b – 光标移动到所在单词词首。

f – 移动到光标所在单词词末。

t – 交换最后两个单词。

u – 将当前单词光标后的字母转为大写。

l – 将当前单词光标后的字母转为小写。

r – 撤销对从历史记录中带来的命令的修改。

. （注意末尾的点号） – 使用上一条命令的最后一个单词。

</code></pre>

<h2 id="toc_4">功能分类</h2>

<p><img src="http://pb9nlfw6h.bkt.clouddn.com/15307621177428.jpg" alt=""/></p>

<h3 id="toc_5">剪切板操作</h3>

<pre><code>Ctrl+Shift+C  复制
Ctrl+Shift+V  粘贴
</code></pre>

<h3 id="toc_6">光标操作</h3>

<pre><code>Ctrl+A(ahead)      将光标移动到命令行开头相当于VIM里shift+^
Ctrl+E(end)    将光标移动到命令行结尾处相当于VIM里shift+$
Ctrl+LeftArrow(方向键左键)      光标移动到上一个单词的词首
Ctrl+RightArrow(方向键右键)    光标移动到下一个单词的词尾
Ctrl+F(forwards)    光标向后移动一个字符,相当与→;VIM里l
Ctrl+B(backwards) 光标向前移动一个字符,相当与←;VIM里h
Ctrl+X       在上次光标所在字符和当前光标所在字符之间跳转
Esc+B    移动到当前单词的开头
Esc+F    移动到当前单词的结尾
</code></pre>

<h3 id="toc_7">文本处理操作</h3>

<pre><code>Ctrl+U    剪切光标至行首的内容 相当于VIM里d shift+^
Ctrl+K    剪切光标至行尾的内容 相当于VIM里d shift+$
Ctrl+W  剪切光标到词首的内容 相当于VIM里db
Alt+D    剪切光标到词尾的内容
Ctrl+D    删除光标所在字符 相当于Delete;VIM里x或者dl
Ctrl+H    删除光标前的字符 相当于Backspace;VIM里hx或者dh
Ctrl+Y    粘贴刚才所删除的字符(ctrl+u上次执行时删除的字符)
Ctrl+7    恢复刚刚的内容
Ctrl+(X U)      撤销刚才的操作（按住Ctrl的同时再先后按x和u）
Esc+T    颠倒光标相邻单词的位置
Ctrl+T    颠倒光标相邻字符的位置，并将光标移动到下一个字符
Alt+C      将光标所在字符到词尾改为首字母大写
Alt+U      将光标所在字符到词尾转化为大写
Alt+L      将光标所在字符到词尾转化为小写
Alt+R       撤消前一次动作
Ctrl+V    插入特殊字符,如Ctrl+(V Tab)加入Tab字符键
Ctrl+?      撤消前一次输入
Ctrl+(X X)   在EOL和当前光标位置移动
^oldstr^newstr    替换前一次命令中字符串   
</code></pre>

<h3 id="toc_8">任务处理操作</h3>

<pre><code>Ctrl+C    删除整行/终止
Ctrl+L    刷新屏幕
Ctrl+S    挂起当前shell
Ctrl+Q    重新启用挂起的shell
</code></pre>

<h3 id="toc_9">标签页处理操作</h3>

<pre><code>Shift+Ctrl+T        新建标签页
Shift+Ctrl+W        关闭标签页
Ctrl+PageUp         前一标签页
Ctrl+PageDown       后一标签页
Shift+Ctrl+PageUp   标签页左移
Shift+Ctrl+PageDown 标签页右移
Alt+1,2,3...        切换到标签页1,2,3...
</code></pre>

<h3 id="toc_10">窗口操作</h3>

<pre><code>Shift+Ctrl+N    新建窗口
Shift+Ctrl+Q    关闭终端
F11             全屏
Ctrl+Plus       放大
Ctrl+Minus      减小
Ctrl+0          原始大小
Shift+UpArrow   向上滚屏
Shift+DownArrow 向下滚屏
Shift+PageUp    向上翻页
Shift+PageDown  向下翻页
</code></pre>

<h3 id="toc_11">历史命令操作</h3>

<pre><code>↑(Ctrl+P(previous))      显示上一条命令
↑(Ctrl+N(next))         显示下一条命令
Ctrl+R(retrieve) String  搜索包含String字符串的命令/继续向上检索(Ctrl+S         向下检索)
Ctrl+r                  然后输入若干字符，开始向上搜索包含该字符的命令，继续按Ctrl+r，搜索上一条匹配的命令
Ctrl+s                  与Ctrl+r类似,只是正向检索
Alt+&lt;                   历史列表第一项
Alt+&gt;                   历史列表最后一项
Alt+Shift+,             历史列表第一项
Alt+Shift+.             历史列表最后一项
!$                      以上一条命令的参数做为其参数
!Num                    执行命令历史列表的第Num条命令
!!                      执行上一条命令
!?String?               执行含有String字符串的最新命令
!-n -                   倒数第N条历史命令
!-n:p -                 打印上一条命令（不执行）
!-n:gs/str1/str2/ -     将倒数第N条命令的str1替换为str2，并执行（若不加g,则仅替换第一个）
ls !$                   执行命令ls，并以上一条命令的参数为其参数
</code></pre>

<h3 id="toc_12">其他操作</h3>

<pre><code>Ctrl+M(Ctrl+O)          相当于Enter
Esc x3(Tab x2)(Ctrl+I)  显示所有支持的命令
Ctrl+【                  相当于Esc
Ctrl+X(Shift+2)         显示可能hostname补全
Ctrl+S                  锁住终端
Ctrl+Q                  解锁终端
alt+数字键               操作的次数
Ctrl+Alt+Backspace      杀死图形化桌面会话，把你返回到登录屏幕。
Ctrl+Alt+Delete         关机和重新引导 
Ctrl+Alt+[Fn]           切换屏幕。 从 [F1] 到 [F6] 是 shell 提示屏幕， [F7] 是图形化屏幕。
Alt+Tab                 在图形化桌面环境中切换任务。在打开的任务和应用程序间切换。
</code></pre>

<h2 id="toc_13">参考：</h2>

<p><a href="https://www.cnblogs.com/nucdy/p/5251659.html">https://www.cnblogs.com/nucdy/p/5251659.html</a><br/>
<a href="https://www.cnblogs.com/webzhangnan/p/3221410.html">https://www.cnblogs.com/webzhangnan/p/3221410.html</a><br/>
<a href="https://blog.csdn.net/guyongqiangx/article/details/80602552">https://blog.csdn.net/guyongqiangx/article/details/80602552</a><br/>
<a href="https://www.linuxidc.com/Linux/2017-10/147757.htm">https://www.linuxidc.com/Linux/2017-10/147757.htm</a></p>

<h2 id="toc_14">示例操作</h2>

<pre><code>c+l  清屏先

minuit@suse:~&gt;str1 str2 str3  #输入三个单词发现第一单词需要大写好按c+a跳到开头按a+c

minuit@suse:~&gt; Str1 str2 str3  #好现在单词就变成了现在这个样子,又发现第二个单词要全大写(这样的命令真是玩死人:( )好吧如果你当前光标在第二个单词,那直接a+u把这个单词改变,如果不在的话那按住c+a接着c+f跳到第二个单词那再a+u就OK了结果像下面所示

。

minuit@suse:~&gt; Str1 STR2 str3   #我想换过来怎么办我的位置已经在最后一个单词这个好办按住a+2+b哈哈跳到了第二个单词再来一下a+l这下第二个单词全小写了,再来一个比较典型的例子

[url]http://bbs.chinaunix.net/viewthread.php?tid=842595[/url]

标题:如何将数据文件中的每个词的第一个字母变成大写？

哈哈这个难不到我们吧因为我们已经会了a+c了

minuit@suse:~&gt; welcome to chinaunix!   #不就是变个大小写吗按住c+a接着a+3+c看看效果

minuit@suse:~&gt; Welcome To Chinaunix!  #GOOD很简单

我们再来试试替换

minuit@suse:~&gt; Welcome To Chinaunix!  #还是这三单词c+a跳到开头再接着跳到第二个单词那(因为a+t只能跟前一个单词做替换所以不能在第一个单词按a+t)按住a+t

minuit@suse:~&gt; To Welcome Chinaunix!  #现在成这样子的了如果我用再按a+2+t那又变了一个样

minuit@suse:~&gt; Chinaunix!  Welcome To   #好了来一点比较常用的

minuit@suse:~&gt;ls /tmp/               #看看下面有些什么

file1 file2 file3 ..... ..

minuit@suse:~&gt;^ls^cd         #现在再又想进入目录很简单的健入替换命令就行了在命令很长时用这个替换可以省掉很多按a+b或a+f的时间

cd /tmp/

minuit@suse:/tmp&gt;   #进入了tmp目录了

跳转的命令就不试了大家自己体会试也看不见^_^   

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IPMI-DELL]]></title>
    <link href="www.anhaoker.com/15287735246134.html"/>
    <updated>2018-06-12T11:18:44+08:00</updated>
    <id>www.anhaoker.com/15287735246134.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">Server端：</h2>

<h3 id="toc_1">编译安装</h3>

<p>在安装zabbix服务器的时候需要带参数---with-openipmi</p>

<h3 id="toc_2">修改配置</h3>

<p>cat /etc/zabbix/zabbix_server.conf |grep IPMI</p>

<pre><code>StartIPMIPollers=20

范围在0-1000选择，看你自己监控的ipmi主机的多少
</code></pre>

<h3 id="toc_3">导入监控模板</h3>

<pre><code>模板下载地址: https://share.zabbix.com/index.php?option=com_mtree&amp;task=att_download&amp;link_id=642&amp;cf_id=39
</code></pre>

<p>添加监控主机，关联上本模板，并在IPMI页面</p>

<pre><code>设置Authentication algorithm为Default, Privilege level为User, Username为root, Password为CNvWCYX98Yf^?Bd，保存即可
</code></pre>

<p><img src="http://p97r6m0sf.bkt.clouddn.com/15287912031450.jpg" alt=""/></p>

<p>cannot connect to IPMI host: [16777411] Unknown error 16777411<br/>
<img src="http://p97r6m0sf.bkt.clouddn.com/15287953505554.jpg" alt=""/></p>

<h2 id="toc_4">Agent端</h2>

<h3 id="toc_5">安装IPMItool软件包并开启IPMI服务</h3>

<pre><code>yum install -y OpenIPMI ipmitool
service ipmi start
</code></pre>

<h3 id="toc_6">配置IPMI地址:</h3>

<pre><code>ipmitool lan set 1 ipaddr 10.100.4.114
ipmitool lan set 1 netmask 255.255.255.0
ipmitool lan set 1 defgw ipaddr 10.100.4.1
ipmitool lan print 1
</code></pre>

<p>将本机的IPMI地址配置为10.100.4.114/24,网关为10.100.4.1</p>

<h3 id="toc_7">开启IPMI Over LAN</h3>

<pre><code>ipmitool lan set 1 access on
</code></pre>

<h3 id="toc_8">配置用户</h3>

<p>本次的需求为监控服务器传感器信息，只需要USER级别用户即可.</p>

<pre><code>ipmitool user set name 2 root 
ipmitool user set password 2 CNvWCYX98Yf^?Bd
ipmitool channel setaccess 1 2 callin=on ipi=on link=on privilege=4 

ipmitool user set name 15 bdyg_ipmi
ipmitool user set password 15 MrGVC8V[m8ci#Mi
ipmitool user enable 15
ipmitool user priv 15 2 1
ipmitool user list 1
</code></pre>

<p>将建立id为15，用户名为bdyg_ipmi，密码为MrGVC8V[m8ci#Mi,权限为User(对应2)</p>

<h3 id="toc_9">测试</h3>

<p>登录Zabbix服务器，通过ipmitool远程访问Dell服务器传感器信息</p>

<pre><code>#查看用户信息
ipmitool -H 10.100.4.111 -I lanplus  -Uroot -PCNvWCYX98Yf^?Bd user list                         
#查看传感器信息
pmitool -H 10.100.4.111 -I lanplus  -Uroot -PCNvWCYX98Yf^?Bd sensor list
ipmitool -H 10.100.4.111 -I lanplus  -Uroot -PCNvWCYX98Yf^?Bd sensor get &quot;Inlet Temp&quot; 

#查看机器电源状态
ipmitool -H 10.100.4.111 -I lanplus  -Uroot -PCNvWCYX98Yf^?Bd chassis power status 

#查看机器硬件信息
ipmitool -H 10.100.4.111 -I lanplus  -Uroot -PCNvWCYX98Yf^?Bd fru
</code></pre>

<p>参考：<br/>
<a href="http://pengyao.org/zabbix-monitor-ipmi-1.html">http://pengyao.org/zabbix-monitor-ipmi-1.html</a><br/>
<a href="https://my.oschina.net/davehe/blog/88801">https://my.oschina.net/davehe/blog/88801</a><br/>
<a href="http://blog.51cto.com/tanght/1116586">http://blog.51cto.com/tanght/1116586</a><br/>
<a href="http://www.cnblogs.com/zhangxinglong/p/7424810.html">http://www.cnblogs.com/zhangxinglong/p/7424810.html</a><br/>
<a href="https://blog.csdn.net/satsuma_samurai/article/details/74940145">https://blog.csdn.net/satsuma_samurai/article/details/74940145</a><br/>
<a href="https://zhiliao.h3c.com/theme/details/20216">https://zhiliao.h3c.com/theme/details/20216</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[VM WARE esxi]]></title>
    <link href="www.anhaoker.com/15286986347471.html"/>
    <updated>2018-06-11T14:30:34+08:00</updated>
    <id>www.anhaoker.com/15286986347471.html</id>
    <content type="html"><![CDATA[
<p>先了解下官方给的模板<br/>
<img src="http://p97r6m0sf.bkt.clouddn.com/15287047191127.jpg" alt=""/></p>

<p>zabbix 编译要支持–with-libxml2 和 –with-libcurl(前者用来解析调用SOAP接口返回的XML，后者用来调用vcenter的SOAP接口),</p>

<h2 id="toc_0">servers 配置文件</h2>

<p>vim /etc/zabbix/zabbix_server.conf</p>

<pre><code>#VM ware ESXI
StartVMwareCollectors=4
VMwarePerfFrequency=60
VMwareCacheSize=200M

StartVMwareCollectors（0-250） 只有大于0时才能是该功能生效，意为预先配置的vmware监控实例数量。
VMwareCacheSize（256K-2G）内存中维护的vmware集群结构的大小，建议80M。
VMwareFrequency（10-864000）zabbix获取更新vmware集群结构的最小间隔时间，单位为分钟。

</code></pre>

<h2 id="toc_1">ZABBIX UI配置</h2>

<pre><code>建议远程登录vcenter创建一个只读用户进行数据的读取

{$URL} - 输入vCenter SDK URL (https://vcenter ip/sdk)
{$USERNAME} - 登录vCenter使用的用户名，一般是administrator@vsphere.local
{$PASSWORD} - 登录vCenter使用的密码
</code></pre>

<p><img src="http://p97r6m0sf.bkt.clouddn.com/15287037867343.jpg" alt=""/><br/>
<img src="http://p97r6m0sf.bkt.clouddn.com/15287038113714.jpg" alt=""/><br/>
<img src="http://p97r6m0sf.bkt.clouddn.com/15287038987381.jpg" alt=""/></p>

<p>参考：<br/>
<a href="https://www.zabbix.com/documentation/3.4/zh/manual/vm_monitoring">https://www.zabbix.com/documentation/3.4/zh/manual/vm_monitoring</a></p>

<p><a href="https://github.com/ameiji/Zabbix-VMware-Templates/blob/master/COPYING">https://github.com/ameiji/Zabbix-VMware-Templates/blob/master/COPYING</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IO监控]]></title>
    <link href="www.anhaoker.com/15284429017864.html"/>
    <updated>2018-06-08T15:28:21+08:00</updated>
    <id>www.anhaoker.com/15284429017864.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1、磁盘状态：cat /proc/diskstats</h2>

<h3 id="toc_1">server ui 配置</h3>

<h4 id="toc_2">导入模板</h4>

<p><img src="http://p97r6m0sf.bkt.clouddn.com/15284431940772.jpg" alt=""/></p>

<h4 id="toc_3">添加自动发现规则(如果没有则创建)</h4>

<p><img src="http://p97r6m0sf.bkt.clouddn.com/15284438467669.jpg" alt=""/></p>

<h3 id="toc_4">agent 配置</h3>

<h4 id="toc_5">配置文件</h4>

<p>vim /etc/zabbix/zabbix_agentd.conf.d/userparameter_iostat.conf</p>

<pre><code>UserParameter=custom.vfs.dev.discovery,/etc/zabbix/zabbix_scripts/dev-discovery.sh
UserParameter=iostat[*],/etc/zabbix/zabbix_scripts/iostat-chk.sh $1 $2
UserParameter=disk.status[*],/bin/bash /etc/zabbix/zabbix_scripts/check_disk.sh -d $1 -o $2
</code></pre>

<h4 id="toc_6">脚本</h4>

<p>cat /etc/zabbix/zabbix_scripts/dev-discovery.sh</p>

<pre><code>#!/bin/bash

DEVICES=`iostat | awk &#39;{ if ($1 ~ &quot;^([shxv]|xv)d[a-z]$&quot;) { print $1 } }&#39;`

COUNT=`echo &quot;$DEVICES&quot; | wc -l`
INDEX=0
echo &#39;{&quot;data&quot;:[&#39;
echo &quot;$DEVICES&quot; | while read LINE; do
    echo -n &#39;{&quot;{#DEVNAME}&quot;:&quot;&#39;$LINE&#39;&quot;}&#39;
    INDEX=`expr $INDEX + 1`
    if [ $INDEX -lt $COUNT ]; then
        echo &#39;,&#39;
    fi
done
echo &#39;]}&#39;
</code></pre>

<p>或</p>

<pre><code>#!/bin/bash

diskarray=(`cat /proc/diskstats |grep -E &quot;\bsd[abcdefg]\b|\bxvd[abcdefg]\b&quot;|grep -i &quot;\b$1\b&quot;|awk &#39;{print $3}&#39;|sort|uniq   2&gt;/dev/null`)
length=${#diskarray[@]}

printf &quot;{\n&quot;printf  &#39;\t&#39;&quot;\&quot;data\&quot;:[&quot;

for ((i=0;i&lt;$length;i++))

do
        printf &#39;\n\t\t{&#39;
        printf &quot;\&quot;{#DISK_NAME}\&quot;:\&quot;${diskarray[$i]}\&quot;}&quot;
        if [ $i -lt $[$length-1] ];then
                printf &#39;,&#39;
        fi
done
printf  &quot;\n\t]\n&quot;printf &quot;}\n&quot;
</code></pre>

<p>cat /etc/zabbix/zabbix_scripts/check_disk.sh </p>

<pre><code>#!/bin/sh 
# 80 sda 76880282531 8117316 937263519846 4237854729 62989000438 35668103347 777694636224 1190396494 3 2895102137 899093508 
while getopts &quot;d:o:&quot; opt 
do 
case $opt in 
d ) disk=$OPTARG;; 
o ) option=$OPTARG;; 
? ) 
echo &#39;parameter is wrong!&#39; 
exit 1;; 
esac 
done 
if [ ! &quot;${disk}&quot; ] || [ ! &quot;${option}&quot; ];then 
echo &quot;parameter is null&quot; 
exit 1 
fi 
if [[ ${option} == &quot;read&quot; ]];then 
cat /proc/diskstats |grep &quot;${disk} &quot;|awk &#39;{print $6}&#39; 
elif [[ ${option} == &quot;write&quot; ]];then 
cat /proc/diskstats |grep &quot;${disk} &quot;|awk &#39;{print $10}&#39; 
elif [[ ${option} == &quot;readops&quot; ]];then 
cat /proc/diskstats |grep &quot;${disk} &quot;|awk &#39;{print $4}&#39; 
elif [[ ${option} == &quot;writeops&quot; ]];then 
cat /proc/diskstats |grep &quot;${disk} &quot;|awk &#39;{print $8}&#39; 
elif [[ ${option} == &quot;readtime&quot; ]];then 
cat /proc/diskstats |grep &quot;${disk} &quot;|awk &#39;{print $7}&#39; 
elif [[ ${option} == &quot;writetime&quot; ]];then 
cat /proc/diskstats |grep &quot;${disk} &quot;|awk &#39;{print $11}&#39; 
fi 
</code></pre>

<p>/etc/init.d/zabbix_agentd restart</p>

<p>cat /proc/diskstats </p>

<pre><code>设备号     编号  设备      读完成次数   合并完成次数      读扇区次数       读操作花费毫秒数    写完成次数       合并写完成次数     写扇区次数       写操作花费的毫秒数       正在处理的输入/输出请求数       输入/输出操作花费的毫秒数       输入/输出操作花费的加权毫秒数。
   8       0    sda       437179787      111140         88148407612     256090773           504526543       4574433         57747952507     870869581                   0                           215482123                           1126127633

从diskstats采集，磁盘使用率计算方式为：
两次采集的输入/输出操作花费的毫秒数之差 / 采集间隔时间

例如：第一次采集输入/输出操作花费的毫秒数为90258834，间隔10秒后采集的值为90258710
那么磁盘使用率为 （90258710ms - 90258834ms）/ 10*1000ms = 0.0124，也就是1.24%
</code></pre>

<p>参考：<br/>
<a href="https://www.aliyun.com/jiaocheng/433252.html">https://www.aliyun.com/jiaocheng/433252.html</a><br/>
<a href="https://www.cnblogs.com/zhangs1986/p/8118788.html">https://www.cnblogs.com/zhangs1986/p/8118788.html</a><br/>
<a href="https://www.cnblogs.com/dachenzi/p/8232001.html">https://www.cnblogs.com/dachenzi/p/8232001.html</a></p>

<h2 id="toc_7">2. IOSTAT状态</h2>

<h3 id="toc_8">server ui 配置</h3>

<h4 id="toc_9">导入模板</h4>

<p><a href="media/15284429017864/zbx_export_templates%20-1-.xml">zbx_export_templates -1-</a></p>

<h4 id="toc_10">添加自动发现规则(如果没有则创建)</h4>

<h3 id="toc_11">agent 配置</h3>

<h4 id="toc_12">配置文件</h4>

<h4 id="toc_13">脚本</h4>

<p>自动发现脚本：<br/>
cat /etc/zabbix/zabbix_scripts/dev-discovery.sh</p>

<pre><code>#!/bin/bash

DEVICES=`iostat | awk &#39;{ if ($1 ~ &quot;^([shxv]|xv)d[a-z]$&quot;) { print $1 } }&#39;`

COUNT=`echo &quot;$DEVICES&quot; | wc -l`
INDEX=0
echo &#39;{&quot;data&quot;:[&#39;
echo &quot;$DEVICES&quot; | while read LINE; do
    echo -n &#39;{&quot;{#DEVNAME}&quot;:&quot;&#39;$LINE&#39;&quot;}&#39;
    INDEX=`expr $INDEX + 1`
    if [ $INDEX -lt $COUNT ]; then
        echo &#39;,&#39;
    fi
done
echo &#39;]}&#39;
</code></pre>

<p>数据采集脚本<br/>
cat /etc/zabbix/zabbix_scripts/disk_status.sh</p>

<pre><code>#/bin/sh
device=$1
item=$2

/usr/bin/iostat -dxkt 2 2 &gt; /var/log/zabbix/iostat_output 2&gt;/dev/null

case $item in

rrqm)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot;|tail -1|awk &#39;{print $2}&#39;
;;

wrqm)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot;|tail -1|awk &#39;{print $3}&#39;
;;

rps)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot;|tail -1|awk &#39;{print $4}&#39;
;;

wps)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $5}&#39;
;;

rKBps)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $6}&#39;
;;

wKBps)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $7}&#39;
;;

avgrq-sz)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $8}&#39;
;;

avgqu-sz)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $9}&#39;
;;

await)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $10}&#39;
;;

r_await)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $11}&#39;
;;

w_await)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $12}&#39;
;;

svctm)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $13}&#39;
;;

util)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $14}&#39;
;;
esac
</code></pre>

<p>/etc/init.d/zabbix_agentd restart</p>

<p>参考：</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[zookeeper]]></title>
    <link href="www.anhaoker.com/15284264486830.html"/>
    <updated>2018-06-08T10:54:08+08:00</updated>
    <id>www.anhaoker.com/15284264486830.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[docker]]></title>
    <link href="www.anhaoker.com/15284264396270.html"/>
    <updated>2018-06-08T10:53:59+08:00</updated>
    <id>www.anhaoker.com/15284264396270.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[redis]]></title>
    <link href="www.anhaoker.com/15284264338352.html"/>
    <updated>2018-06-08T10:53:53+08:00</updated>
    <id>www.anhaoker.com/15284264338352.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mongodb]]></title>
    <link href="www.anhaoker.com/15284264265436.html"/>
    <updated>2018-06-08T10:53:46+08:00</updated>
    <id>www.anhaoker.com/15284264265436.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mysql]]></title>
    <link href="www.anhaoker.com/15284264221433.html"/>
    <updated>2018-06-08T10:53:42+08:00</updated>
    <id>www.anhaoker.com/15284264221433.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[nginx]]></title>
    <link href="www.anhaoker.com/15284264147825.html"/>
    <updated>2018-06-08T10:53:34+08:00</updated>
    <id>www.anhaoker.com/15284264147825.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM]]></title>
    <link href="www.anhaoker.com/15284264028937.html"/>
    <updated>2018-06-08T10:53:22+08:00</updated>
    <id>www.anhaoker.com/15284264028937.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[配置报警-邮件和微信]]></title>
    <link href="www.anhaoker.com/15284261636485.html"/>
    <updated>2018-06-08T10:49:23+08:00</updated>
    <id>www.anhaoker.com/15284261636485.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">配置邮箱发送报警</a>
<ul>
<li>
<a href="#toc_1">安装部署脚本</a>
</li>
<li>
<a href="#toc_2">UI配置</a>
<ul>
<li>
<a href="#toc_3">1、【报警媒介类型】</a>
</li>
<li>
<a href="#toc_4">2、【用户】</a>
</li>
<li>
<a href="#toc_5">3、【动作】</a>
</li>
<li>
<a href="#toc_6">4、【触发器】</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">配置邮箱发送报警</h2>

<h3 id="toc_1">安装部署脚本</h3>

<p>报警需要在server上安装sendEmail客户端，并进行配置用。<br/>
使用自定义脚本媒介。zabbix 会将信息传递给脚本,接下来你在 脚本里面随意处理,一共会传递三个参数,按顺序接受也就是\(1,\)2,$3 了,为了方便记忆,一般分别给他们赋值到 To\Subject\body.</p>

<pre><code>
下载安装
cd /usr/local/src
wget http://caspian.dotconf.net/menu/Software/SendEmail/sendEmail-v1.56.tar.gz
tar zxf sendEmail-v1.56.tar.gz
cp sendEmail-v1.56/sendEmail /usr/local/sbin/


测试发送报警
/usr/local/sbin/sendEmail -f tl_zabbix@163.com -t &quot;weihoop@gmail.com&quot; -s smtp.163.com -u &quot;zabbix&quot; -o message-content-type=html -o message-charset=utf8 -xu tl_zabbix@163.com -xp tuling999 -m &quot;zabbix alart&quot;
Dec 07 16:01:57 localhost sendEmail[6009]: Email was sent successfully!


创建发邮件脚本
mkdir /etc/zabbix/alertscripts
vi /etc/zabbix/alertscripts/sendEmail.sh

#!/bin/bash
TO=$1
SUBJECT=$2
BODY=$3

#/usr/local/sbin/sendEmail -f tl_alarm@sina.com  -t &quot;$TO&quot; -s smtp.sina.com  -u &quot;$SUBJECT&quot; -o message-content-type=html -o message-charset=utf8 -xu tl_alarm@sina.com -xp z2qUwLuEWW2z -m &quot;$BODY&quot;
/usr/local/sbin/sendEmail -f zabbix@bd-yg.com  -t &quot;$TO&quot; -s smtp.bd-yg.com  -u &quot;$SUBJECT&quot; -o message-content-type=html -o message-charset=utf8 -xu zabbix@bd-yg.com -xp Agj7vBJQ#9Fewnbm -m &quot;$BODY&quot;


echo $TO &gt;&gt; /tmp/zabbix_mail.txt
echo $SUBJECT &gt;&gt; /tmp/zabbix_mail.txt
echo $BODY &gt;&gt; /tmp/zabbix_mail.txt

</code></pre>

<p><strong>注意检查 /etc/zabbix/zabbix_server.conf 里，是否配置了：AlertScriptsPath=/etc/zabbix/alertscripts</strong></p>

<h3 id="toc_2">UI配置</h3>

<h4 id="toc_3">1、【报警媒介类型】</h4>

<pre><code>点击【管理】-【报警媒介类型】-【创建媒体类型】，依次选择/脚本

名称：sendEmail
类型：脚本
脚本名称：sendEmail.sh
脚本参数：
{ALERT.SENDTO}
{ALERT.SUBJECT}
{ALERT.MESSAGE}
</code></pre>

<p><img src="media/15284261636485/15284372215486.jpg" alt=""/><br/>
<img src="media/15284261636485/15284372310677.jpg" alt=""/></p>

<h4 id="toc_4">2、【用户】</h4>

<p>可以设置一个用户组有多个邮箱，也可以为每一个用户设置单独邮箱（在报警动作里使用）<br/>
<code><br/>
[管理】- 【用户】 - 【报警媒介】<br/>
添加媒介：sendEmail<br/>
添加联系人的邮箱<br/>
</code></p>

<p><img src="media/15284261636485/15284374193098.jpg" alt=""/><br/>
<img src="media/15284261636485/15284374373503.jpg" alt=""/><br/>
<img src="media/15284261636485/15284374447086.jpg" alt=""/></p>

<h4 id="toc_5">3、【动作】</h4>

<p>打开[配置】- 【动作】- 【触发器】，点击【创建动作】</p>

<pre><code>名称：
Action-SendEmail

条件：
A 维护状态非在维护
B 触发器值 = 问题或预警级别


默认接收人：
【{TRIGGER.STATUS}】{HOSTNAME1}_{HOST.IP}: {TRIGGER.NAME}

默认信息：
告警主机:{HOSTNAME1} &lt;br/&gt;
告警时间:{EVENT.DATE} {EVENT.TIME} &lt;br/&gt;
告警等级:{TRIGGER.SEVERITY} &lt;br/&gt;
告警信息: {TRIGGER.NAME} &lt;br/&gt;
告警项目:{TRIGGER.KEY1} &lt;br/&gt;
问题详情:{ITEM.NAME}:{ITEM.VALUE} &lt;br/&gt;
当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1} &lt;br/&gt;
事件ID:{EVENT.ID} &lt;br/&gt;

恢复主题：
【{TRIGGER.STATUS}】{HOSTNAME1}_{HOST.IP}: {TRIGGER.NAME}

恢复信息：
告警主机:{HOSTNAME1} &lt;br/&gt;
告警时间:{EVENT.DATE} {EVENT.TIME} &lt;br/&gt;
告警等级:{TRIGGER.SEVERITY} &lt;br/&gt;
告警信息: {TRIGGER.NAME} &lt;br/&gt;
告警项目:{TRIGGER.KEY1} &lt;br/&gt;
问题详情:{ITEM.NAME}:{ITEM.VALUE} &lt;br/&gt;
当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1} &lt;br/&gt;
事件ID:{EVENT.ID} &lt;br/&gt;


操作：
默认操作步骤持续时间:60s
步骤：1 - 1（报警次数）
步骤持续时间：0(多次报警间隔时间)
操作类型：发送消息
发送到用户群组：zabbix administrator （选择用户组）
发送到用户：admin ...（选择用户发送）
仅发送到：所有（使用哪个动作发送）

点击【更新】完成操作。

</code></pre>

<p><img src="media/15284261636485/15284359553660.jpg" alt=""/><br/>
<img src="media/15284261636485/15284359963275.jpg" alt=""/><br/>
<img src="media/15284261636485/15284360397670.jpg" alt=""/></p>

<h4 id="toc_6">4、【触发器】</h4>

<p>参考：<br/>
<a href="https://blog.csdn.net/weixin_37998647/article/details/78931163">https://blog.csdn.net/weixin_37998647/article/details/78931163</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[自动发现设置]]></title>
    <link href="www.anhaoker.com/15284261175013.html"/>
    <updated>2018-06-08T10:48:37+08:00</updated>
    <id>www.anhaoker.com/15284261175013.html</id>
    <content type="html"><![CDATA[
<p>配置监控模板</p>

<pre><code>定义自动发现
zabbix自动发现配置,功能是 zabbix server 去扫一个网段,把在线的主机添加到 Host 列表中。
zabbix客户端自动注册，正好相反,这次是 Active agent 主动联系 zabbix server,最后由 zabbix server 将这些 agent 加到 host 里。
对于需要部署特别多服务器的人来说,这功能相当给力。所有服务器批量装好 zabbix agent,server 配置好 trigger, 所有的服务器都配置好了,非常快速。
1. 配置
修改配置文件修
指定 server ip
cat /etc/zabbix/zabbix_agentd.conf | grep -E ^ServerActive
ServerActive=172.18.100.232
修改 Hostname
cat /usr/local/zabbix-2.2.1/etc/zabbix_agentd.conf | grep -E ^Hostname
Hostname=auto-reg-for-mayg-01
关于主机名:如果 zabbix_agentd.conf 配置有定义 Hostname,那么 zabbix 会使用这个 Hostname 命名,否则 agent 的主机名(hostname 得来的)
修改 metadataitem
cat /usr/local/zabbix-2.2.1/etc/zabbix_agentd.conf | grep HostMetadataItem=
HostMetadataItem=system.uname
2. 配置action(动作)
依次点击：配置 - 动作 - 自动注册 - 创建动作。
在【动作】菜单里，输入：
名称：Action_for_自动注册
默认接收人：Auto registration: {HOST.HOST}
默认信息：
Host name: {HOST.HOST}
Host IP: {HOST.IP}
Agent port: {HOST.PORT}
在【条件】菜单里，输入：
标签：A
名称：主机元数据 似 Linux
在【操作】菜单里，输入：
操作类型：添加主机
添加到主机群组: Linux servers
链接到模板: Template App Zabbix Agent, Template ICMP Ping, Template OS Linux
点击更新后，完成配置。
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Alertmanager报警模块]]></title>
    <link href="www.anhaoker.com/15270467833243.html"/>
    <updated>2018-05-23T11:39:43+08:00</updated>
    <id>www.anhaoker.com/15270467833243.html</id>
    <content type="html"><![CDATA[
<pre><code>Overview
Alertmanager与Prometheus是相互分离的两个部分。Prometheus服务器根据报警规则将警报发送给Alertmanager，然后Alertmanager将silencing、inhibition、aggregation等消息通过电子邮件、PaperDuty和HipChat发送通知。

设置警报和通知的主要步骤：

安装配置Alertmanager
配置Prometheus通过-alertmanager.url标志与Alertmanager通信
在Prometheus中创建告警规则
Alertmanager简介及机制
Alertmanager处理由类似Prometheus服务器等客户端发来的警报，之后需要删除重复、分组，并将它们通过路由发送到正确的接收器，比如电子邮件、Slack等。Alertmanager还支持沉默和警报抑制的机制。

分组
分组是指当出现问题时，Alertmanager会收到一个单一的通知，而当系统宕机时，很有可能成百上千的警报会同时生成，这种机制在较大的中断中特别有用。

例如，当数十或数百个服务的实例在运行，网络发生故障时，有可能服务实例的一半不可达数据库。在告警规则中配置为每一个服务实例都发送警报的话，那么结果是数百警报被发送至Alertmanager。

但是作为用户只想看到单一的报警页面，同时仍然能够清楚的看到哪些实例受到影响，因此，人们通过配置Alertmanager将警报分组打包，并发送一个相对看起来紧凑的通知。

分组警报、警报时间，以及接收警报的receiver是在配置文件中通过路由树配置的。

抑制
抑制是指当警报发出后，停止重复发送由此警报引发其他错误的警报的机制。

例如，当警报被触发，通知整个集群不可达，可以配置Alertmanager忽略由该警报触发而产生的所有其他警报，这可以防止通知数百或数千与此问题不相关的其他警报。

抑制机制可以通过Alertmanager的配置文件来配置。

沉默
沉默是一种简单的特定时间静音提醒的机制。一种沉默是通过匹配器来配置，就像路由树一样。传入的警报会匹配RE，如果匹配，将不会为此警报发送通知。

沉默机制可以通过Alertmanager的Web页面进行配置。

Alertmanager的配置
Alertmanager通过命令行flag和一个配置文件进行配置。命令行flag配置不变的系统参数、配置文件定义的禁止规则、通知路由和通知接收器。

要查看所有可用的命令行flag，运行alertmanager -h。

Alertmanager在运行时加载配置，如果不能很好的形成新的配置，更改将不会被应用，并记录错误。

配置文件
要指定加载的配置文件，需要使用-config.file标志。该文件使用YAML来完成，通过下面的描述来定义。括号内的参数是可选的，对于非列表的参数的值设置为指定的缺省值。

global:
  # ResolveTimeout is the time after which an alert is declared resolved
  # if it has not been updated.
  [ resolve_timeout: &lt;duration&gt; | default = 5m ]

  # The default SMTP From header field.
  [ smtp_from: &lt;tmpl_string&gt; ]
  # The default SMTP smarthost used for sending emails.
  [ smtp_smarthost: &lt;string&gt; ]

  # The API URL to use for Slack notifications.
  [ slack_api_url: &lt;string&gt; ]

  [ pagerduty_url: &lt;string&gt; | default = &quot;https://events.pagerduty.com/generic/2010-04-15/create_event.json&quot; ]
  [ opsgenie_api_host: &lt;string&gt; | default = &quot;https://api.opsgenie.com/&quot; ]

# Files from which custom notification template definitions are read.
# The last component may use a wildcard matcher, e.g. &#39;templates/*.tmpl&#39;.
templates:
  [ - &lt;filepath&gt; ... ]

# The root node of the routing tree.
route: &lt;route&gt;

# A list of notification receivers.
receivers:
  - &lt;receiver&gt; ...

# A list of inhibition rules.
inhibit_rules:
  [ - &lt;inhibit_rule&gt; ... ]

路由 route
路由块定义了路由树及其子节点。如果没有设置的话，子节点的可选配置参数从其父节点继承。

每个警报进入配置的路由树的顶级路径，顶级路径必须匹配所有警报（即没有任何形式的匹配）。然后匹配子节点。如果continue的值设置为false，它在匹配第一个孩子后就停止；如果在子节点匹配，continue的值为true，警报将继续进行后续兄弟姐妹的匹配。如果警报不匹配任何节点的任何子节点（没有匹配的子节点，或不存在），该警报基于当前节点的配置处理。

路由配置格式
[ receiver: &lt;string&gt; ]
[ group_by: &#39;[&#39; &lt;labelname&gt;, ... &#39;]&#39; ]

# Whether an alert should continue matching subsequent sibling nodes.
[ continue: &lt;boolean&gt; | default = false ]

# A set of equality matchers an alert has to fulfill to match the node.
match:
  [ &lt;labelname&gt;: &lt;labelvalue&gt;, ... ]

# A set of regex-matchers an alert has to fulfill to match the node.
match_re:
  [ &lt;labelname&gt;: &lt;regex&gt;, ... ]

# How long to initially wait to send a notification for a group
# of alerts. Allows to wait for an inhibiting alert to arrive or collect
# more initial alerts for the same group. (Usually ~0s to few minutes.)
[ group_wait: &lt;duration&gt; ]

# How long to wait before sending notification about new alerts that are
# in are added to a group of alerts for which an initial notification
# has already been sent. (Usually ~5min or more.)
[ group_interval: &lt;duration&gt; ]

# How long to wait before sending a notification again if it has already
# been sent successfully for an alert. (Usually ~3h or more).
[ repeat_interval: &lt;duration&gt; ]

# Zero or more child routes.
routes:
  [ - &lt;route&gt; ... ]

示例：

# The root route with all parameters, which are inherited by the child
# routes if they are not overwritten.
route:
  receiver: &#39;default-receiver&#39;
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  group_by: [cluster, alertname]
  # All alerts that do not match the following child routes
  # will remain at the root node and be dispatched to &#39;default-receiver&#39;.
  routes:
  # All alerts with service=mysql or service=cassandra
  # are dispatched to the database pager.
  - receiver: &#39;database-pager&#39;
    group_wait: 10s
    match_re:
      service: mysql|cassandra
  # All alerts with the team=frontend label match this sub-route.
  # They are grouped by product and environment rather than cluster
  # and alertname.
  - receiver: &#39;frontend-pager&#39;
    group_by: [product, environment]
    match:
      team: frontend

抑制规则 inhibit_rule
抑制规则，是存在另一组匹配器匹配的情况下，静音其他被引发警报的规则。这两个警报，必须有一组相同的标签。

抑制配置格式
# Matchers that have to be fulfilled in the alerts to be muted.
target_match:
  [ &lt;labelname&gt;: &lt;labelvalue&gt;, ... ]
target_match_re:
  [ &lt;labelname&gt;: &lt;regex&gt;, ... ]

# Matchers for which one or more alerts have to exist for the
# inhibition to take effect.
source_match:
  [ &lt;labelname&gt;: &lt;labelvalue&gt;, ... ]
source_match_re:
  [ &lt;labelname&gt;: &lt;regex&gt;, ... ]

# Labels that must have an equal value in the source and target
# alert for the inhibition to take effect.
[ equal: &#39;[&#39; &lt;labelname&gt;, ... &#39;]&#39; ]

接收器 receiver
顾名思义，警报接收的配置。

通用配置格式
# The unique name of the receiver.
name: &lt;string&gt;

# Configurations for several notification integrations.
email_configs:
  [ - &lt;email_config&gt;, ... ]
pagerduty_configs:
  [ - &lt;pagerduty_config&gt;, ... ]
slack_config:
  [ - &lt;slack_config&gt;, ... ]
opsgenie_configs:
  [ - &lt;opsgenie_config&gt;, ... ]
webhook_configs:
  [ - &lt;webhook_config&gt;, ... ]

邮件接收器 email_config
# Whether or not to notify about resolved alerts.
[ send_resolved: &lt;boolean&gt; | default = false ]

# The email address to send notifications to.
to: &lt;tmpl_string&gt;
# The sender address.
[ from: &lt;tmpl_string&gt; | default = global.smtp_from ]
# The SMTP host through which emails are sent.
[ smarthost: &lt;string&gt; | default = global.smtp_smarthost ]

# The HTML body of the email notification.
[ html: &lt;tmpl_string&gt; | default = &#39;{{ template &quot;email.default.html&quot; . }}&#39; ] 

# Further headers email header key/value pairs. Overrides any headers
# previously set by the notification implementation.
[ headers: { &lt;string&gt;: &lt;tmpl_string&gt;, ... } ]

Slack接收器 slack_config
# Whether or not to notify about resolved alerts.
[ send_resolved: &lt;boolean&gt; | default = true ]

# The Slack webhook URL.
[ api_url: &lt;string&gt; | default = global.slack_api_url ]

# The channel or user to send notifications to.
channel: &lt;tmpl_string&gt;

# API request data as defined by the Slack webhook API.
[ color: &lt;tmpl_string&gt; | default = &#39;{{ if eq .Status &quot;firing&quot; }}danger{{ else }}good{{ end }}&#39; ]
[ username: &lt;tmpl_string&gt; | default = &#39;{{ template &quot;slack.default.username&quot; . }}&#39;
[ title: &lt;tmpl_string&gt; | default = &#39;{{ template &quot;slack.default.title&quot; . }}&#39; ]
[ title_link: &lt;tmpl_string&gt; | default = &#39;{{ template &quot;slack.default.titlelink&quot; . }}&#39; ]
[ pretext: &lt;tmpl_string&gt; | default = &#39;{{ template &quot;slack.default.pretext&quot; . }}&#39; ]
[ text: &lt;tmpl_string&gt; | default = &#39;{{ template &quot;slack.default.text&quot; . }}&#39; ]
[ fallback: &lt;tmpl_string&gt; | default = &#39;{{ template &quot;slack.default.fallback&quot; . }}&#39; ]

Webhook接收器 webhook_config
# Whether or not to notify about resolved alerts.
[ send_resolved: &lt;boolean&gt; | default = true ]

# The endpoint to send HTTP POST requests to.
url: &lt;string&gt;

Alertmanager会使用以下的格式向配置端点发送HTTP POST请求：

{
  &quot;version&quot;: &quot;2&quot;,
  &quot;status&quot;: &quot;&lt;resolved|firing&gt;&quot;,
  &quot;alerts&quot;: [
    {
      &quot;labels&quot;: &lt;object&gt;,
      &quot;annotations&quot;: &lt;object&gt;,
      &quot;startsAt&quot;: &quot;&lt;rfc3339&gt;&quot;,
      &quot;endsAt&quot;: &quot;&lt;rfc3339&gt;&quot;
    },
    ...
  ]
}

报警规则
报警规则允许你定义基于Prometheus语言表达的报警条件，并发送报警通知到外部服务。

定义报警规则
报警规则通过以下格式定义：

ALERT &lt;alert name&gt;
  IF &lt;expression&gt;
  [ FOR &lt;duration&gt; ]
  [ LABELS &lt;label set&gt; ]
  [ ANNOTATIONS &lt;label set&gt; ]

FOR子句使得Prometheus等待第一个传进来的向量元素（例如高HTTP错误的实例），并计数一个警报。如果元素是active，但是没有firing的，就处于pending状态。

LABELS（标签）子句允许指定一组附加的标签附到警报上。现有的任何标签都会被覆盖，标签值可以被模板化。

ANNOTATIONS（注释）子句指定另一组未查明警报实例的标签，它们被用于存储更长的其他信息，例如警报描述或者链接，注释值可以被模板化。

报警规则示例
# Alert for any instance that is unreachable for &gt;5 minutes.
ALERT InstanceDown
  IF up == 0
  FOR 5m
  LABELS { severity = &quot;page&quot; }
  ANNOTATIONS {
    summary = &quot;Instance {{ $labels.instance }} down&quot;,
    description = &quot;{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.&quot;,
  }

# Alert for any instance that have a median request latency &gt;1s.
ALERT APIHighRequestLatency
  IF api_http_request_latencies_second{quantile=&quot;0.5&quot;} &gt; 1
  FOR 1m
  ANNOTATIONS {
    summary = &quot;High request latency on {{ $labels.instance }}&quot;,
    description = &quot;{{ $labels.instance }} has a median request latency above 1s (current value: {{ $value }}s)&quot;,
  }

发送警报通知
Prometheus可以周期性的发送关于警报状态的信息到Alertmanager实例，然后Alertmanager调度来发送正确的通知。该Alertmanager可以通过-alertmanager.url命令行flag来配置。
</code></pre>

<p><a href="https://blog.csdn.net/y_xiao_/article/details/50818451">https://blog.csdn.net/y_xiao_/article/details/50818451</a></p>

<p><a href="https://www.cnblogs.com/iiiiher/p/8277040.html">https://www.cnblogs.com/iiiiher/p/8277040.html</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[运维监控工作规划]]></title>
    <link href="www.anhaoker.com/15264350522088.html"/>
    <updated>2018-05-16T09:44:12+08:00</updated>
    <id>www.anhaoker.com/15264350522088.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">运维监控面临的问题</a>
</li>
<li>
<a href="#toc_1">运维监控目前的现状</a>
</li>
<li>
<a href="#toc_2">运维监控软件的选择</a>
</li>
<li>
<a href="#toc_3">运维监控的规划</a>
<ul>
<li>
<a href="#toc_4">短期规划</a>
</li>
<li>
<a href="#toc_5">中期规划</a>
</li>
<li>
<a href="#toc_6">长期规划</a>
</li>
</ul>
</li>
<li>
<a href="#toc_7">总结</a>
</li>
</ul>


<h2 id="toc_0">运维监控面临的问题</h2>

<p>公司项目上线：针对docker容器及k8s的性能监控，项目监控<br/>
操作系统监控：针对传统和公有云系统的性能监控，文件监控，<br/>
硬件设备监控：私有云硬件设备监控<br/>
网络监控：对网络设备及流量监控<br/>
应用服务监控：模板的选择，日志监控<br/>
预警处理：整合报警信息，自动处理</p>

<p>报警方案：值班方案，故障处理预案，阈值，监控日志错误次数<br/>
监控自动化部署：针对客户端批量部署<br/>
图形规范：zabbix _grafna-聚合添加规范<br/>
攻击安全处理方案及预案：</p>

<h2 id="toc_1">运维监控目前的现状</h2>

<p>zabbix——系统和服务<br/>
    模板：功能不全，<br/>
    监控项：监控信息准确性，具体的指标含义需加深理解并项目实际情况进行重点选择<br/>
    图形：图形类型，正确绘图<br/>
    触发器：阀值设置的范围，不同应用场景独特的需求<br/>
    报警方式：邮件和微信有延时情况出现（系统性能），频繁的报警<br/>
    架构及优化：前端和数据库分离，主动模式和被动模式的选择</p>

<p>天兔——数据库<br/>
    慢日志：不能实时查询<br/>
    社区：不活跃<br/>
    安全性：非可靠</p>

<h2 id="toc_2">运维监控软件的选择</h2>

<p>zabbix<br/>
    硬件信息-IPMI：物理机服务器系列<br/>
    网络设备-SNMP：交换机、防火墙<br/>
    系统状态-agent：linux等<br/>
    应用服务-agent/JMX：tomcat、nginx、mongoDB、redis、mysql等<br/>
    项目状态-TCP：URL状态、全链路</p>

<p>prometheus<br/>
    容器监控-node_export：docker、k8s集群<br/>
    网络状态-SNMP/node_export：容器数据流量</p>

<p>天兔<br/>
    mysql<br/>
    mongodb<br/>
    redis</p>

<p>商业监控：<br/>
阿里云，<br/>
UCLOAD</p>

<h2 id="toc_3">运维监控的规划</h2>

<h3 id="toc_4">短期规划</h3>

<p>时间节点：7月份公司项目上线<br/>
目标状态：实现对公司项目上线应用的状态监控，实现正确的预警功能</p>

<p><img src="media/15264350522088/15264557141758.jpg" alt=""/></p>

<h3 id="toc_5">中期规划</h3>

<p>时间节点：公司项目上线后2-4个月<br/>
目标状态：对公司项目的监控项进行调整和优化，实现预处理功能<br/>
<img src="media/15264350522088/15264558484466.jpg" alt=""/></p>

<h3 id="toc_6">长期规划</h3>

<p>时间节点：公司运维平台CMDB上线<br/>
目标状态：整合监控状态到公司运维平台，实现自动化运维<br/>
<img src="media/15264350522088/15264558634812.jpg" alt=""/></p>

<h2 id="toc_7">总结</h2>

<p>后续待完善</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[# Prometheus 简介及安装]]></title>
    <link href="www.anhaoker.com/15258517853636.html"/>
    <updated>2018-05-09T15:43:05+08:00</updated>
    <id>www.anhaoker.com/15258517853636.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>什么是 Prometheus</p>

<p>主要功能</p>

<p>核心组件</p>

<p>基础架构</p>

<p>安装部署监控系统</p>
</blockquote>

<h2 id="toc_0">什么是 Prometheus</h2>

<p>Prometheus 是由 SoundCloud 开源监控告警解决方案，从 2012 年开始编写代码，再到 2015 年 github 上开源以来，已经吸引了 9k+ 关注，以及很多大公司的使用；2016 年 Prometheus 成为继 k8s 后，第二名 CNCF(Cloud Native Computing Foundation) 成员。<br/>
作为新一代开源解决方案，很多理念与 Google SRE 运维之道不谋而合。</p>

<h2 id="toc_1">主要功能</h2>

<ul>
<li><p>多维 数据模型（时序由 metric 名字和 k/v 的 labels 构成）。</p></li>
<li><p>灵活的查询语句（PromQL）。</p></li>
<li><p>无依赖存储，支持 local 和 remote 不同模型。</p></li>
<li><p>采用 http 协议，使用 pull 模式，拉取数据，简单易懂。</p></li>
<li><p>监控目标，可以采用服务发现或静态配置的方式。</p></li>
<li><p>支持多种统计数据模型，图形化友好。</p></li>
</ul>

<h2 id="toc_2">核心组件</h2>

<ol>
<li>Prometheus Server， 主要用于抓取数据和存储时序数据，另外还提供查询和 Alert Rule 配置管理。</li>
<li>client libraries，用于对接 Prometheus Server, 可以查询和上报数据。</li>
<li>push gateway ，用于批量，短期的监控数据的汇总节点，主要用于业务数据汇报等。</li>
<li>各种汇报数据的 exporters ，例如汇报机器数据的 node_exporter, 汇报 MongoDB 信息的 MongoDB exporter 等等。</li>
<li>用于告警通知管理的 alertmanager 。</li>
</ol>

<h2 id="toc_3">基础架构</h2>

<p>下面这张图说明了Prometheus的整体架构，以及生态中的一些组件作用:</p>

<p><img src="http://p1ly7m2xj.bkt.clouddn.com/15245483444586.jpg" alt=""/></p>

<p>从这个架构图，也可以看出 Prometheus 的主要模块包含， Server, Exporters, Pushgateway, PromQL, Alertmanager, WebUI 等。</p>

<p>它大致使用逻辑是这样：</p>

<ol>
<li>Prometheus server 定期从静态配置的 targets 或者服务发现的 targets 拉取数据。</li>
<li>当新拉取的数据大于配置内存缓存区的时候，Prometheus 会将数据持久化到磁盘（如果使用 remote storage 将持久化到云端）。</li>
<li>Prometheus 可以配置 rules，然后定时查询数据，当条件触发的时候，会将 alert 推送到配置的 Alertmanager。</li>
<li>Alertmanager 收到警告的时候，可以根据配置，聚合，去重，降噪，最后发送警告。</li>
<li>可以使用 API， Prometheus Console 或者 Grafana 查询和聚合数据。</li>
</ol>

<h2 id="toc_4">注意</h2>

<ul>
<li><p>Prometheus 的数据是基于时序的 float64 的值，如果你的数据值有更多类型，无法满足。</p></li>
<li><p>Prometheus 不适合做审计计费，因为它的数据是按一定时间采集的，关注的更多是系统的运行瞬时状态以及趋势，即使有少量数据没有采集也能容忍，但是审计计费需要记录每个请求，并且数据长期存储，这个和 Prometheus 无法满足，可能需要采用专门的审计系统。</p></li>
</ul>

<h2 id="toc_5">安装部署</h2>

<h3 id="toc_6">1. 环境说明</h3>

<table>
<thead>
<tr>
<th>角色</th>
<th>IP地址</th>
<th>OS</th>
</tr>
</thead>

<tbody>
<tr>
<td>Prometheus Server <br> Grafana Server</td>
<td>10.100.4.181</td>
<td>Centos7.4</td>
</tr>
<tr>
<td>Prometheus Node</td>
<td>10.100.4.182</td>
<td>Centos7.4</td>
</tr>
</tbody>
</table>

<h3 id="toc_7">2. 软件包版本</h3>

<p>Prometheus 下载： <a href="https://github.com/prometheus/prometheus/releases/download/v2.2.1/prometheus-2.2.1.linux-amd64.tar.gz">https://github.com/prometheus/prometheus/releases/download/v2.2.1/prometheus-2.2.1.linux-amd64.tar.gz</a></p>

<p>node_exporter 下载：<a href="https://github.com/prometheus/node_exporter/releases/download/v0.15.1/node_exporter-0.15.1.linux-amd64.tar.gz">https://github.com/prometheus/node_exporter/releases/download/v0.15.1/node_exporter-0.15.1.linux-amd64.tar.gz</a></p>

<p>Grafana 下载：<a href="https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.6.2-1.x86_64.rpm">https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.6.2-1.x86_64.rpm</a></p>

<h3 id="toc_8">3. 部署 Prometheus</h3>

<p><strong>下载</strong></p>

<pre><code class="language-bash">$ cd /usr/local/src/
$ wget https://github.com/prometheus/prometheus/releases/download/v2.2.1/prometheus-2.2.1.linux-amd64.tar.gz
</code></pre>

<p><strong>部署到/usr/local/目录</strong><br/>
<strong>promethus不用编译安装，解压目录中有配置文件与启动文件</strong></p>

<pre><code class="language-bash">$ tar xf prometheus-2.2.1.linux-amd64.tar.gz -C /usr/local/
$ cd /usr/local/
$ ln -sv prometheus-2.2.1.linux-amd64 prometheus
</code></pre>

<p><strong>验证</strong></p>

<pre><code class="language-bash">$ cd prometheus
$ ./prometheus --version
</code></pre>

<p><strong>配置文件</strong></p>

<pre><code class="language-bash"># 解压目录中的 prometheus.yml
# my global config
global:
  scrape_interval:     15s # 设置抓取(pull)时间间隔，默认是1m
  evaluation_interval: 15s # 设置rules评估时间间隔，默认是1m
  # scrape_timeout is set to the global default (10s).

# 告警管理配置，暂未使用，默认配置
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      # - alertmanager:9093

# 加载rules，并根据设置的时间间隔定期评估，暂未使用，默认配置
rule_files:
  # - &quot;first_rules.yml&quot;
  # - &quot;second_rules.yml&quot;

# 这里就表示抓取对象的配置
# 这里是抓去promethues自身的配置
scrape_configs:
  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.
  - job_name: &#39;prometheus&#39;

    # metrics_path defaults to &#39;/metrics&#39;
    # scheme defaults to &#39;http&#39;.
    # 重写了全局抓取间隔时间，由15秒重写成5秒。
    scrape_interval: 5s

    static_configs:
      - targets: [&#39;localhost:9090&#39;]
  # 新添加的对其它node节点抓取数据
  - job_name: &quot;linux&quot;
    scrape_interval: 10s
    
    static_configs:
      - targets: [&#39;10.100.4.182:9100&#39;]
</code></pre>

<p><strong>创建用户</strong></p>

<pre><code class="language-bash">$ groupadd prometheus
$ useradd -g prometheus -s /sbin/nologin prometheus
$ chown -R prometheus.prometheus /usr/local/prometheus
</code></pre>

<p><strong>创建 Systemd 服务</strong></p>

<pre><code class="language-bash">$ vim /usr/lib/systemd/system/prometheus.service

[unit]
Description=Prometheus Server
Documentation=https://prometheus.io/docs/introduction/overview/
After=network.target

[Service]
Restart=on-failure
WorkingDirectory=/usr/local/prometheus/
ExecStart=/usr/local/prometheus/prometheus
-config.file=/usr/local/prometheus/prometheus.yml

[Install]
WantedBy=multi-user.target
</code></pre>

<p><strong>设置 iptables 规则</strong></p>

<pre><code class="language-bash">-A INPUT -p tcp -m state --state NEW -m tcp --dport 9090 -j ACCEPT
</code></pre>

<p><strong>验证服务状态</strong></p>

<pre><code class="language-bash">$ ss -tnl | grep 9090
</code></pre>

<p><img src="http://p1ly7m2xj.bkt.clouddn.com/15245551884229.jpg" alt=""/></p>

<p>访问 Prometheus 自带的 Web，访问方式： IP:Port</p>

<p><img src="http://p1ly7m2xj.bkt.clouddn.com/15245553219848.jpg" alt=""/></p>

<h3 id="toc_9">4. 部署 node_exporter</h3>

<p>Node_exporter 收集机器的系统数据，这里采用 prometheus 官方提供的exporter，除 node_exporter 外，官方还提供 consul，memcached，haproxy，mysqld 等 exporter，具体可查看官网。</p>

<p><strong>1. 下载&amp;部署</strong></p>

<pre><code class="language-bash"># 下载
$ cd /usr/local/src/
$ wget https://github.com/prometheus/node_exporter/releases/download/v0.15.1/node_exporter-0.15.1.linux-amd64.tar.gz

# 部署
$ tar xf node_exporter-0.15.2.linux-amd64.tar.gz -C /usr/local/
$ cd /usr/local/
$ mv node_exporter-0.15.2.linux-amd64 node_exporter
</code></pre>

<p><strong>2. 设置用户</strong></p>

<pre><code class="language-bash">$ groupadd prometheus
$ useradd -g prometheus -s /sbin/nologin prometheus
$ chown -R prometheus:prometheus /usr/local/node_exporter/
</code></pre>

<p><strong>3. 创建 Systemd 服务</strong></p>

<pre><code class="language-bash">$ vim /usr/lib/systemd/system/node_exporter.service

[Unit]
Description=node_exporter
Documentation=https://prometheus.io/
After=network.target

[Service]
Type=simple
User=prometheus
ExecStart=/usr/local/node_exporter/node_exporter
Restart=on-failure

[Install]
WantedBy=multi-user.target

# 启动 node_exporter
$ systemctl enable node_exporte
$ systemctl start node_exporter
</code></pre>

<p><strong>4. 设置 iptables 规则</strong></p>

<pre><code class="language-bash"># 官方node_exporter默认使用9100端口
-A INPUT -p tcp -m state --state NEW -m tcp --dport 9100 -j ACCEPT
</code></pre>

<p><strong>5. 验证</strong></p>

<p>访问 <a href="http://10.100.4.181:9090">http://10.100.4.181:9090</a> ，可见node1主机已经可被监控，如下：</p>

<p><img src="http://p1ly7m2xj.bkt.clouddn.com/15245561697241.jpg" alt=""/></p>

<h3 id="toc_10">5. 部署 Grafana</h3>

<p>在 Prometheus&amp; Grafana Server节点部署 Grafana 服务。</p>

<p><strong>1. 下载&amp;安装</strong></p>

<pre><code class="language-bash"># 下载
$ cd /usr/local/src
$ wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.6.2-1.x86_64.rpm

# 安装
$ yum -y localinstall grafana-4.6.2-1.x86_64.rpm
</code></pre>

<p><strong>2. 配置文件</strong></p>

<p>配置文件位于/etc/grafana/grafana.ini，这里暂时保持默认配置即可。</p>

<p><strong>3. 设置开机启动</strong></p>

<pre><code class="language-bash">$ systemctl enable grafana-server
$ systemctl start grafana-server
</code></pre>

<p><strong>4. 设置iptables</strong></p>

<pre><code class="language-bash"># grafana-server默认使用3000端口

-A INPUT -p tcp -m state --state NEW -m tcp --dport 3000 -j ACCEPT
</code></pre>

<p><strong>5. 添加数据源</strong></p>

<p>1）登录</p>

<p>访问：<a href="http://10.100.4.181:3000%EF%BC%8C%E9%BB%98%E8%AE%A4%E8%B4%A6%E5%8F%B7/%E5%AF%86%E7%A0%81%EF%BC%9Aadmin/admin">http://10.100.4.181:3000，默认账号/密码：admin/admin</a></p>

<p><img src="http://p1ly7m2xj.bkt.clouddn.com/15245580334189.jpg" alt=""/></p>

<p>2）添加数据源</p>

<p>在登陆首页，点击&quot;Add data source&quot;按钮，跳转到添加数据源页面，配置如下：</p>

<p>Name: prometheus</p>

<p>Type: prometheus</p>

<p>URL: <a href="http://localhost:9090/">http://localhost:9090/</a></p>

<p>Access: proxy</p>

<p>取消Default的勾选，其余默认，点击&quot;Add&quot;，如下：</p>

<p><img src="http://p1ly7m2xj.bkt.clouddn.com/15245583370506.jpg" alt=""/></p>

<p><strong>6. 导入dashboard</strong><br/>
从grafana官网下载相关dashboaed到本地，如：<a href="https://grafana.com/dashboards/1860">https://grafana.com/dashboards/1860</a><br/>
Grafana首页--&gt;左上角图标--&gt;Dashboard--&gt;import</p>

<p><img src="http://p1ly7m2xj.bkt.clouddn.com/15245585398765.jpg" alt=""/></p>

<p>Upload已下载至本地的json文件（或者使用dashboard id，如这里的1860），如下：</p>

<p><img src="http://p1ly7m2xj.bkt.clouddn.com/15245587856972.jpg" alt=""/></p>

<p>数据源选择&quot;prometheus&quot;，即添加的数据源name，点击&quot;Import&quot;按钮，如下：</p>

<p><img src="http://p1ly7m2xj.bkt.clouddn.com/15245588409973.jpg" alt=""/></p>

<p><strong>7. 查看dashboard</strong><br/>
Grafana首页--&gt;左上角图标--&gt;Dashboard--&gt;Home，Home 下拉列表中可见有已添加的 dashboard  ：</p>

<p><img src="http://p1ly7m2xj.bkt.clouddn.com/15245633321269.jpg" alt=""/></p>

<p>另一个 dashboard 我觉得也不错下载地址 <a href="https://grafana.com/dashboards/159">https://grafana.com/dashboards/159</a> 如下图：</p>

<p><img src="http://p1ly7m2xj.bkt.clouddn.com/15245640521897.jpg" alt=""/></p>

<h3 id="toc_11">参考文档</h3>

<p><a href="https://www.linuxidc.com/Linux/2018-01/150354.htm">https://www.linuxidc.com/Linux/2018-01/150354.htm</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[部署 Prometheus 基础环境]]></title>
    <link href="www.anhaoker.com/15258308100903.html"/>
    <updated>2018-05-09T09:53:30+08:00</updated>
    <id>www.anhaoker.com/15258308100903.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">部署和配置 Prometheu+Alertmanager+Grafana 监控系统</a>
<ul>
<li>
<a href="#toc_1">部署 Prometheus</a>
</li>
<li>
<a href="#toc_2">部署 Alertmanager</a>
<ul>
<li>
<a href="#toc_3">安装Alertmanager</a>
</li>
<li>
<a href="#toc_4">配置Alertmanager</a>
<ul>
<li>
<a href="#toc_5">alert.rules</a>
</li>
<li>
<a href="#toc_6">simply.yml (微信和邮件)</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_7">部署 Grafana</a>
<ul>
<li>
<a href="#toc_8">安装 Grafana</a>
</li>
<li>
<a href="#toc_9">添加Prometheus数据源</a>
</li>
<li>
<a href="#toc_10">报警配置</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_11">配置 Prometheus 常用 exporter</a>
<ul>
<li>
<a href="#toc_12">部署node_export</a>
<ul>
<li>
<a href="#toc_13">源码安装</a>
</li>
<li>
<a href="#toc_14">Docker方式安装</a>
</li>
</ul>
</li>
<li>
<a href="#toc_15">snmp_exporter 安装</a>
</li>
<li>
<a href="#toc_16">BlackBox exporter 安装</a>
</li>
</ul>
</li>
<li>
<a href="#toc_17">通过容器部署 Prometheus+Grafana+cAdvisor</a>
</li>
<li>
<a href="#toc_18">其它参考:</a>
</li>
</ul>


<h2 id="toc_0">部署和配置 Prometheu+Alertmanager+Grafana 监控系统</h2>

<p><img src="http://image-bdyg.test.upcdn.net/2018/05/23/15258344265165.jpg" alt=""/></p>

<h3 id="toc_1">部署 Prometheus</h3>

<pre><code>从https://prometheus.io/download/ 选择合适的版本进行下载，

wget  https://github.com/prometheus/prometheus/releases/download/v2.2.1/prometheus-2.2.1.linux-amd64.tar.gz
tar xvf prometheus-2.2.1.linux-amd64.tar.gz
mv prometheus-2.2.1.linux-amd64 prometheus
cd prometheus
./prometheus --version
cp prometheus.yml prometheus.yml_bk

---------------------------------------------------------- 
# 全局配置
global:
  scrape_interval:     15s # 设置抓取(pull)时间间隔，默认是1m
  evaluation_interval: 15s # 设置rules评估时间间隔，默认是1m
  # scrape_timeout is set to the global default (10s).

# 告警管理配置
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      # - alertmanager:9093

# 加载rules，并根据设置的时间间隔定期评估，暂未使用，默认配置
rule_files:
  # - &quot;first_rules.yml&quot;
  # - &quot;second_rules.yml&quot;

# 这里就表示抓取对象的配置
# 这里是抓去promethues自身的配置
scrape_configs:
  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.
  - job_name: &#39;prometheus&#39;

    # metrics_path defaults to &#39;/metrics&#39;
    # scheme defaults to &#39;http&#39;.

    static_configs:
      - targets: [&#39;localhost:9090&#39;]

  # 新添加的对其它node节点抓取数据
  - job_name: &quot;linux&quot;
    static_configs:
      - targets: [&#39;127.0.0.1:9100&#39;]

---------------------------------------------------------------

#创建prometheus的用户
主目录为/var/lib/prometheus，用作prometheus的数据目录。

groupadd prometheus
useradd -g prometheus -m -d /var/lib/prometheus -s /sbin/nologin prometheus
chown -R prometheus.prometheus /usr/local/prometheus/

#创建Systemd服务
vim /usr/lib/systemd/system/prometheus.service
---------------------------------------------------------------
[Unit]
Description=prometheus
After=network.target
[Service]
Type=simple
User=prometheus
ExecStart=/usr/local/prometheus/prometheus --config.file=/usr/local/prometheus/prometheus.yml --storage.tsdb.path=/var/lib/prometheus
Restart=on-failure
[Install]
WantedBy=multi-user.target
---------------------------------------------------------------

systemctl restart prometheus.service
systemctl enable prometheus.service
</code></pre>

<p><strong>Prometheus自带一个比较简单的Web，可以查看表达式搜索结果、报警配置、prometheus配置,exporter状态等。自带Web默认在<a href="http://ip:9090">http://ip:9090</a></strong></p>

<p><img src="http://image-bdyg.test.upcdn.net/2018/05/23/15258466523377.jpg" alt=""/></p>

<p><strong>Prometheus本身也是自带exporter的,我们通过请求 <a href="http://ip:9090/metrics">http://ip:9090/metrics</a> 可以查看从exporter中能具体抓到哪些数据。</strong></p>

<p><img src="http://image-bdyg.test.upcdn.net/2018/05/23/15258467915021.jpg" alt=""/></p>

<h3 id="toc_2">部署 Alertmanager</h3>

<p>Alertmanager 是一个告警系统，通过设置规则，可以实现告警通知。</p>

<p>相关文档:</p>

<pre><code>Prometheus Alertmanager报警组件
http://www.jianshu.com/p/239b145e2acc https://github.com/prometheus/alertmanager
Prometheus监控 - Alertmanager报警模块 
https://sagittariusyx.github.io/2016/03/07/prometheus-alertmanager/ 
https://github.com/prometheus/alertmanager

Alert template:
https://prometheus.io/blog/2016/03/03/custom-alertmanager-templates/

Sending alert notifications to multiple destinations
https://www.robustperception.io/sending-alert-notifications-to-multiple-destinations/

Alert tree:
https://prometheus.io/webtools/alerting/routing-tree-editor/
</code></pre>

<h4 id="toc_3">安装Alertmanager</h4>

<pre><code>cd /usr/local/prometheus
wget https://github.com/prometheus/alertmanager/releases/download/v0.14.0/alertmanager-0.14.0.linux-amd64.tar.gz
tar xvf alertmanager-0.14.0.linux-amd64.tar.gz
mv alertmanager-0.14.0.linux-amd64 alertmanager
cd alertmanager

chown -R prometheus.prometheus /usr/local/prometheus/ /var/lib/prometheus/

#创建Systemd服务
vim /usr/lib/systemd/system/alertmanager.service
---------------------------------------------------------------
[Unit]
Description=alertmanager
After=network.target
[Service]
Type=simple
User=prometheus
ExecStart=/usr/local/prometheus/alertmanager/alertmanager --config.file=/usr/local/prometheus/alertmanager/simple.yml --storage.path=/var/lib/prometheus
Restart=on-failure
[Install]
WantedBy=multi-user.target
---------------------------------------------------------------

systemctl restart alertmanager.service
</code></pre>

<p>**也可以通过加载配置文件方式而不重启Alertmanager服务: **<br/>
curl -X POST <a href="http://localhost:9093/-/reload">http://localhost:9093/-/reload</a></p>

<p><strong>访问Alertmanager页面</strong><br/>
<a href="http://172.18.100.58:9093/#/alters">http://172.18.100.58:9093/#/alters</a></p>

<p><img src="http://image-bdyg.test.upcdn.net/2018/05/23/15258491774888.jpg" alt=""/></p>

<h4 id="toc_4">配置Alertmanager</h4>

<p>报警分两部分，报警条件规则文件默认放在Prometheus安装目录下，文件名为 alert.rules；具体通知内容设置在Alertmanager安装目录下的simply.yml文件，例如邮件地址和通知人员。</p>

<p>以下是一些基础配置，阈值和时间根据自己需求进行修改。</p>

<h5 id="toc_5">alert.rules</h5>

<p>测试配置-当使用率大于2%时候(测试),发邮件报警</p>

<pre><code>groups:
- name: test-rule
  rules:
  - alert: NodeMemoryUsage
    expr: (node_memory_MemTotal - (node_memory_MemFree+node_memory_Buffers+node_memory_Cached )) / node_memory_MemTotal * 100 &gt; 2
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: &quot;{{$labels.instance}}: High Memory usage detected&quot;
      description: &quot;{{$labels.instance}}: Memory usage is above 80% (current value is: {{ $value }}&quot;

- name: zabbix
  rules:
  - alert: server_status
    expr: up{job=&quot;zabbix&quot;} == 0
    for: 15s
    annotations:
      summary: &quot;机器 {{ $labels.instance }}&quot;
</code></pre>

<h5 id="toc_6">simply.yml (微信和邮件)</h5>

<p>主要分三部分, Global部分设置发送邮件服务器信息，route设置规则和报警时间间隔等，receivers设置接收人。</p>

<pre><code>global:
  smtp_smarthost: &#39;smtp.ym.163.com:25&#39;
  smtp_from: &#39;zabbix@bd-yg.com&#39;
  smtp_auth_username: &#39;zabbix@bd-yg.com&#39;
  smtp_auth_password: &#39;Agj7vBJQ#9Fewnbm&#39;

templates:
  - &#39;/usr/local/prometheus/alertmanager/template/*.tmpl&#39;

route:
  group_by: [&#39;alertname&#39;, &#39;cluster&#39;, &#39;service&#39;]
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 10m
  receiver: &#39;team-X-mails&#39;

receivers:
- name: &#39;team-X-mails&#39;
  email_configs:
  - to: &#39;anhonglei@bd-yg.com&#39;

route:
  group_by: [&#39;alertname&#39;]
  receiver: &#39;wechat&#39;

receivers:
- name: &#39;wechat&#39;
  wechat_configs:
  - corp_id: &#39;ww27addfe9404356b3&#39;
    to_party: &#39;2&#39;
    agent_id: &#39;1000002&#39;
    api_secret: &#39;oWuyrIgg5C0u8N-U9wESRWbb4v3IqOZNg0PhIvIOv2Q&#39;
</code></pre>

<p><strong>设置完毕后需要重新加载配置文件</strong></p>

<h3 id="toc_7">部署 Grafana</h3>

<p>参考文档:<br/>
Configuration:<br/>
<a href="http://docs.grafana.org/installation/configuration/">http://docs.grafana.org/installation/configuration/</a> <br/>
<a href="https://prometheus.io/docs/visualization/grafana/#installing">https://prometheus.io/docs/visualization/grafana/#installing</a><br/>
Setting up Grafana for Prometheus<br/>
<a href="https://www.robustperception.io/setting-up-grafana-for-prometheus/">https://www.robustperception.io/setting-up-grafana-for-prometheus/</a><br/>
Sending alert notifications to multiple destinations<br/>
<a href="https://www.robustperception.io/sending-alert-notifications-to-multiple-destinations/">https://www.robustperception.io/sending-alert-notifications-to-multiple-destinations/</a> <br/>
<a href="https://prometheus.io/docs/visualization/grafana/">https://prometheus.io/docs/visualization/grafana/</a></p>

<h4 id="toc_8">安装 Grafana</h4>

<pre><code>**1. 安装**
wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.1.1-1.x86_64.rpm 
sudo yum localinstall grafana-5.1.1-1.x86_64.rpm 


**2. 配置文件**

配置文件位于/etc/grafana/grafana.ini，这里暂时保持默认配置即可。
配置

1.创建数据库和用户（默认使用的是sqlite3,这里调整为mysql）
$mysql&gt; CREATE DATABASE grafana DEFAULT CHARACTER SET utf8;
$mysql&gt; GRANT ALL ON grafana.* TO grafana@&#39;localhost&#39; IDENTIFIED BY &#39;grafanapassword&#39; WITH GRANT OPTION;
$mysql&gt; FLUSH PRIVILEGES;

2.指定数据库及认证信息
$cp /etc/grafana/grafana.ini{,.default}
$vim /etc/grafana/grafana.ini
[database]
type = mysql
host = 127.0.0.1:3306
name = grafana
user = grafana
password = grafanapassword
ssl_mode = true
ca_cert_path = /opt/mariadb/mariadb-ca.pem
client_key_path = /opt/mariadb/mariadb-client.key
client_cert_path = /opt/mariadb/mariadb-client.pem
server_cert_name = jlive.example.com
[session]
provider = redis
provider_config = addr=127.0.0.1:6379,pool_size=100,db=grafana
cookie_name = grafana_sess
cookie_secure = false
session_life_time = 86400

**3. 设置开机启动**

systemctl enable grafana-server
systemctl start grafana-server

</code></pre>

<h4 id="toc_9">添加Prometheus数据源</h4>

<pre><code>1).Go to http://localhost:3000
2).Enter the username admin and password admin, and then click “Log In”.
3).Click “Data Sources” on the left menu
4).Click “Add new” on the top menu
5).Add a default data source of type Prometheus with http://localhost:9090 as the URL 
6).Click &quot;Add&quot;
Add Dashboard
</code></pre>

<p>1）登录</p>

<p>**访问Grafana Web界面(缺省帐号/密码为admin/admin): **<br/>
<a href="http://172.18.100.58:3000/login">http://172.18.100.58:3000/login</a><br/>
<img src="http://image-bdyg.test.upcdn.net/2018/05/23/15258557406238.jpg" alt=""/></p>

<p>2）添加数据源</p>

<p>在登陆首页，点击&quot;Add data source&quot;按钮<br/>
<img src="http://image-bdyg.test.upcdn.net/2018/05/23/15258558273863.jpg" alt=""/></p>

<p>跳转到添加数据源页面，配置如下：</p>

<pre><code>Name: 测试
Type: prometheus
URL: http://localhost:9090/
Access: Server
</code></pre>

<p><img src="http://image-bdyg.test.upcdn.net/2018/05/23/15258609982630.jpg" alt=""/></p>

<p>添加 dashboard<br/>
<img src="http://image-bdyg.test.upcdn.net/2018/05/23/15258610669456.jpg" alt=""/></p>

<p><strong>6. 在Dashboards页面导入Prometheus Status模板</strong><br/>
从grafana官网下载相关dashboaed到本地，如：<br/>
<a href="https://grafana.com/dashboards/1860">https://grafana.com/dashboards/1860</a><br/>
<a href="https://grafana.com/dashboards/405">https://grafana.com/dashboards/405</a><br/>
<a href="https://grafana.com/dashboards/159">https://grafana.com/dashboards/159</a></p>

<p>Grafana首页--&gt;左上角图标--&gt;create--&gt;import<br/>
<img src="http://image-bdyg.test.upcdn.net/2018/05/23/15258564542751.jpg" alt=""/></p>

<p>数据源选择&quot;prometheus&quot;，即添加的数据源name，点击&quot;Import&quot;按钮，如下：</p>

<p><img src="http://image-bdyg.test.upcdn.net/2018/05/23/15258565709960.jpg" alt=""/><br/>
<img src="http://p1ly7m2xj.bkt.clouddn.com/15245588409973.jpg" alt=""/></p>

<p><strong>7. 查看dashboard</strong><br/>
Grafana首页--&gt;左上角图标--&gt;Dashboard--&gt;Home，Home 下拉列表中可见有已添加的 dashboard  ：</p>

<p><img src="http://image-bdyg.test.upcdn.net/2018/05/23/15258566779564.jpg" alt=""/></p>

<h4 id="toc_10">报警配置</h4>

<h2 id="toc_11">配置 Prometheus 常用 exporter</h2>

<h3 id="toc_12">部署node_export</h3>

<p>为监控服务器CPU、内存、磁盘、I/O等信息，首先需要安装node_exporter。node_exporter的作用是用于机器系统数据收集。除 node_exporter 外，官方还提供 consul，memcached，haproxy，mysqld 等 exporter，具体可查看官网。</p>

<p>可采用直接下载安装和Docker容器方式安装两种</p>

<h4 id="toc_13">源码安装</h4>

<pre><code>**1. 下载&amp;部署**

cd /usr/local/src/
wget https://github.com/prometheus/node_exporter/releases/download/v0.15.2/node_exporter-0.15.2.linux-amd64.tar.gz
tar xf node_exporter-0.15.2.linux-amd64.tar.gz -C /usr/local/
cd /usr/local/
mv node_exporter-0.15.2.linux-amd64 node_exporter


**2. 设置用户**


groupadd prometheus
useradd -g prometheus -s /sbin/nologin prometheus
chown -R prometheus:prometheus /usr/local/node_exporter/


**3. 创建 Systemd 服务**

vim /usr/lib/systemd/system/node_exporter.service
-----------------------
[Unit]
Description=node_exporter
Documentation=https://prometheus.io/
After=network.target

[Service]
Type=simple
User=prometheus
ExecStart=/usr/local/node_exporter/node_exporter
Restart=on-failure

[Install]
WantedBy=multi-user.target
----------------

systemctl enable node_exporter.service
systemctl start node_exporter.service


**4. 设置 iptables 规则**

# 官方node_exporter默认使用9100端口
-A INPUT -p tcp -m state --state NEW -m tcp --dport 9100 -j ACCEPT


**5. 验证**

访问 http://172.18.100.111:9100/metrics ，可见node1主机已经可被监控，如下：

</code></pre>

<h4 id="toc_14">Docker方式安装</h4>

<pre><code># docker pull prom/node-exporter 运行:
# docker run -d \ --net=host \ --restart=always \ --name node-exporter \ -p 9100:9100 \
-v &quot;/proc:/host/proc&quot; \
-v &quot;/sys:/host/sys&quot; \
-v &quot;/:/rootfs&quot; \
prom/node-exporter \
-collector.procfs /host/proc \
-collector.sysfs /host/sys \
-collector.filesystem.ignored-mount-points &quot;^/(sys|proc|dev|host|etc)($|/)&quot;
 
# docker ps -a
CONTAINER
ID IMAGE COMMAND CREATED STATUS
PORTS 2 seconds
NAMES
d5e20da8e3bd hub.allyamall.com/node-exporter &quot;/bin/node_exporte...&quot; ago Up 2 seconds node-exporter
[root@yiche-03 ~]# netstat -anp|grep 9100
tcp6 0 0 :::9100 :::*
tcp6 0 0 192.168.100.29:9100
没有配置--net=host:
# netstat -anp|grep 9100
tcp6 0 0 :::9100 :::*
LISTEN 6200/node_exporter 192.168.100.16:55336 TIME_WAIT -
LISTEN 7687/docker-proxy
# 如果用docker方式安装，但没设置—net=host，在Prometheus/Grafana里将看不到网
卡流量，netstat内容.
# netstat -anp|grep 9100
tcp6 0 0 :::9100 :::* LISTEN 1470/node_exporter
# 设置node_exporter为系统服务
# vim /etc/systemd/system/node_export.service [Unit]
Description=Prometheus NODE Exporter
[Service] WorkingDirectory=/opt/projects/src/src/github.com/prometheus/node_exporter/ ExecStart=/usr/sbin/node_exporter $OPTIONS
[Install]
WantedBy=multi-user.target
# systemctl enable node_export.service # systemctl restart node_export.service
#配置prometheus.yml，对应的node_exporter 端口为9100,例如: #Node exporter
- job_name: &#39;node&#39; static_configs:
- targets: [&#39;127.0.0.1:9100&#39;]

</code></pre>

<h3 id="toc_15">snmp_exporter 安装</h3>

<p>通过 SNMP 监控网络设备</p>

<pre><code># snmp相关的配置文件为/snmp_exporter/snmp.yml，可以通过设置oid方式具体监控网 络设备，也可以直接用默认文件，监控网络设备流量。以下以监控h3c路由器为例。

Documents:
https://www.robustperception.io/snmp-monitoring-with-prometheus/ https://github.com/prometheus/snmp_exporter
SNMP Monitoring with Prometheus
https://www.robustperception.io/snmp-monitoring-with-prometheus/
基于Prometheus的分布式在线服务监控实践 https://zhuanlan.zhihu.com/p/24811652
# 安装: # wget
https://github.com/prometheus/snmp_exporter/releases/download/v0.4.0/snmp_exporter -0.4.0.linux-amd64.tar.gz
# tar xzf snmp_exporter-0.4.0.linux-amd64.tar.gz
# cd snmp_exporter-0.4.0.linux-amd64
#nohup ./snmp_exporter &amp;
[1] 5201
# netstat -anp|grep 9116
    :::*
# 访问http://192.168.100.22:9116/，输入被监控的SNMP主机后可查看该主机信息。
# 在Prometheus.yml里配置snmp信息
# vim /opt/promethens/peometheus.yml # For SNMP equipment
- job_name: &#39;h3c&#39; static_configs:
- targets:
- 192.168.100.1
metrics_path: /snmp params:
module: [default] relabel_configs:
- source_labels: [__address__] target_label: __param_target
- source_labels: [__param_target] target_label: instance
- target_label: __address__
replacement: 127.0.0.1:9116 #SNMP exporter
# 添加snmp_exporter为系统服务
tcp6 0 tcp6 0 tcp6 0
0 :::9116
0 127.0.0.1:9116 0 127.0.0.1:9116
LISTEN 127.0.0.1:59030 127.0.0.1:59026
5201/./snmp_exporte TIME_WAIT - TIME_WAIT -

# vim /etc/systemd/system/snmp_exporter.service
[Unit]
Description=Prometheus SNMP Exporter After=network.target
[Service]
User=root
Group=root WorkingDirectory=/opt/snmp_exporter/ ExecStart=/opt/snmp_exporter/snmp_exporter Type=simple
[Install] WantedBy=multi-user.target
# systemctl enable snmp_exporter.service # systemctl restart snmp_exporter.service
</code></pre>

<h3 id="toc_16">BlackBox exporter 安装</h3>

<pre><code>通过 Ping,http,dns 进行监控
# 安装Blackbox exporter, 源码安装编译的时候可能会提示go路径的问题，所以选择直接 安装。
# go get github.com/prometheus/blackbox_exporter
# go build github.com/prometheus/blackbox_exporter
#启动进程
# cd /opt/projects/bin
# ./blackbox_exporter - config.file=/opt/projects/src/src/github.com/prometheus/blackbox_exporter/blackbox.yml &amp;
[1] 14756
INFO[0000] Starting blackbox_exporter (version=, branch=,
revision=) source=&quot;main.go:153&quot;
INFO[0000] Build context (go=go1.7, user=, date=) source=&quot;main.go:154&quot;
INFO[0000] Loaded config file INFO[0000] Listening on :9115
# netstat -antp|grep 9115 tcp6 0 0 :::9115
source=&quot;main.go:71&quot; source=&quot;main.go:226&quot;
# 浏览器访问:http://192.168.100.22:9115/
# 配置Prometheus.yml，通过ping监控网络设备 #Ping AP
- job_name: &#39;ping&#39;
:::*
LISTEN
14756/./blackbox_ex
 
scrape_interval: 5s metrics_path: /probe params:
module: [icmp] #ping
static_configs:
- targets: [&#39;192.168.100.1&#39;, &#39;192.168.100.11&#39;, &#39;192.168.100.21&#39;, &#39;192.168.100.31&#39;]
labels: groups: &#39;H3C&#39;
# 修改配置后需要重新加载配置文件
</code></pre>

<h2 id="toc_17">通过容器部署 Prometheus+Grafana+cAdvisor</h2>

<pre><code>目的:通过容器方式部署Prometheus+Grafana+cAdvisor,通过轻量式快速部署监控环境 Documents:
1). https://github.com/stefanprodan/dockprom
2). Prometheus/Docker/cAdvisor/Grafana集成监控 https://github.com/stefanprodan/dockprom
3). Grafana 高可用:(Grafana默认使用Sqlite3作为数据库，轻量级，但不支持分布 式，如果要做HA需要用Mysql) http://docs.grafana.org/tutorials/ha_setup/#how-to-setup-grafana-for-high-availability 4).Docker 集群监控平台---cAdvisor-InfluxDB-Grafana https://jevic.github.io/2017/01/23/dockercAdvisordbgra-md/ http://www.2cto.com/net/201701/583599.html
5). 使用InfluxDB+cAdvisor+Grafana配置Docker监控 http://www.jianshu.com/p/d078d353d12f
6).grafana使用mysql存储
https://segmentfault.com/a/1190000008936411
步骤:
# 整个安装组件Prometheus,Grafana,Alertmanager, node_exporter,cAdvisor,全部为容器方 式。
1). 从https://github.com/stefanprodan/dockprom 下载所有代码: $ git clone https://github.com/stefanprodan/dockprom
$ cd dockprom
$ docker-compose up -d
# docker-compose 命令是用来一次性启动管理多个容器的命令，对应的配置文件是
       
docker-compose.yml.
# 如果要单独启动某个容器，例如cAdvisor，可以执行: # sudo docker run \
--volume=/:/rootfs:ro \ --volume=/var/run:/var/run:rw \ --volume=/sys:/sys:ro \ --volume=/var/lib/docker/:/var/lib/docker:ro \ --publish=8080:8080 \
--detach=true \ --name=cadvisor \ google/cadvisor:latest
# 安装完成后直接访问相应的网页和服务即可。
如果单独安装node-exporter,方法如下: # docker pull prom/node-exporter
docker run -d \
--restart=always \
--name node-exporter \
-p 9100:9100 \
-v &quot;/proc:/host/proc&quot; \
-v &quot;/sys:/host/sys&quot; \
-v &quot;/:/rootfs&quot; \
prom/node-exporter \
-collector.procfs /host/proc \
-collector.sysfs /host/sys \
-collector.filesystem.ignored-mount-points &quot;^/(sys|proc|dev|host|etc)($|/)&quot;
#加--restart=always的目的是为了docker系统服务重启的时候容器可以自动重启。 # Prometheus
http://192.168.100.111:9090
# Grafana
http://192.168.100.111:3000
#默认用户名和密码:admin/changeme，添加默认数据库: * Name: Prometheus
* Type: Prometheus
* Url: http://prometheus:9090 * Access: proxy
# 如果需要修改配置文件直接到dockprom 目录下进行修改即可，修改后重新加载配置 生效:
# curl -X POST http://192.168.100.111:9090/-/reload
# 监控cAdvisor报警条件:
  
# vim containers.rules
ALERT cAdvisor_down
IF absent(container_memory_usage_bytes{name=&quot;cadvisor&quot;}) FOR 1m
LABELS { severity = &quot;critical&quot; }
ANNOTATIONS {
summary= &quot;cAdvisor containers down&quot;,
description= &quot;cAdvisor container is down for more than 1 minutes.&quot; }
ALERT cAdvisor_high_cpu
IF sum(rate(container_cpu_usage_seconds_total{name=&quot;cadvisor&quot;}[1m])) /
count(node_cpu{mode=&quot;system&quot;}) * 100 &gt; 10 FOR 5m
LABELS { severity = &quot;warning&quot; } ANNOTATIONS {
summary= &quot;cAdvisor high CPU usage&quot;,
description= &quot;cAdvisor CPU usage is {{ humanize $value}}%.&quot; }
ALERT cAdvisor_high_memory
IF sum(container_memory_usage_bytes{name=&quot;cadvisor&quot;}) &gt; 1200000000 FOR 5m
LABELS { severity = &quot;warning&quot; }
ANNOTATIONS {
summary = &quot;cAdvisor high memory usage&quot;,
description = &quot;cAdvisor memory consumption is at {{ humanize $value}}.&quot;, }
</code></pre>

<h2 id="toc_18">其它参考:</h2>

<pre><code>1). 容器部署完成后可以直接通过docker export导出为tar文件再导入到其它服务器。
导出:
$ docker ps -a
CONTAINER ID IMAGE
NAMES 4da6c4e8d580
COMMAND
CREATED STATUS PORTS
prom/prometheus
hours 0.0.0.0:9090-&gt;9090/tcp prometheus
2cb99ce6b87f prom/node-exporter &quot;/bin/node_exporte...&quot; 13 hours ago hours 9100/tcp nodeexporter
40c02b10c25d grafana/grafana &quot;/run.sh&quot; 13 hours ago Up 13
&quot;/bin/prometheus -...&quot; 13 hours ago
Up 13 Up 13

hours 0.0.0.0:3000-&gt;3000/tcp grafana
b2313d0b3247 prom/alertmanager &quot;/bin/alertmanager...&quot; hours 0.0.0.0:9093-&gt;9093/tcp alertmanager
6a4da9de8ebc google/cadvisor:v0.26.1 &quot;/usr/bin/cadvisor...&quot; hours 8080/tcp cadvisor
$ docker export 6a4da9de8ebc &gt; cadvisor.tar 如果是导出镜像可以使用docker save,导入则是docker load.
导入:
# cat cadvisor.tar | docker import - google/cadvisor:v0.26.1
13 hours ago 13 hours ago
Up 13 Up 13
sha256:cd45ecb65fe4ac1ebdae18baab23529c6597230374eccef27f165c6859f35167
# docker images
REPOSITORY TAG IMAGE ID CREATED SIZE google/cadvisor v0.26.1 cd45ecb65fe4 18 seconds ago 58.1MB
2). Grafana 数据库存放路径:默认Grafana采用Sqlite3，轻量型数据库，但不支持分布 式，如果需要HA可以使用Mysql替代。
#cd /var/lib/grafana
# ll
total 1396
-rw-r--r-- 1 grafana grafana 1422336 Aug 15 15:03 grafana.db drwxr-xr-x 6 grafana grafana 123 Jul 24 10:16 plugins drwx------ 13 grafana grafana 105 Aug 14 08:31 sessions [root@office-monitoring grafana]# du -sh *
1.4M grafana.db 16M plugins 24K sessions

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[prometheus监控调研方案]]></title>
    <link href="www.anhaoker.com/15257584688763.html"/>
    <updated>2018-05-08T13:47:48+08:00</updated>
    <id>www.anhaoker.com/15257584688763.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">简介</a>
<ul>
<li>
<a href="#toc_1">Prometheus 的优点</a>
</li>
<li>
<a href="#toc_2">Prometheus 的特性</a>
</li>
<li>
<a href="#toc_3">Prometheus 的相关组件</a>
</li>
<li>
<a href="#toc_4">Prometheus vs. Zabbix对比</a>
</li>
</ul>
</li>
<li>
<a href="#toc_5">系统架构</a>
</li>
<li>
<a href="#toc_6">数据模型</a>
<ul>
<li>
<a href="#toc_7">度量指标和标签</a>
</li>
<li>
<a href="#toc_8">采样值（Sample）</a>
</li>
<li>
<a href="#toc_9">注解（Notation）</a>
</li>
<li>
<a href="#toc_10">度量指标类型</a>
</li>
<li>
<a href="#toc_11">计数器（Counter）</a>
</li>
<li>
<a href="#toc_12">计量器（Gauge）</a>
</li>
<li>
<a href="#toc_13">直方图（Histogram）</a>
</li>
<li>
<a href="#toc_14">汇总（Summary）</a>
</li>
</ul>
</li>
<li>
<a href="#toc_15">监控的关键指标</a>
<ul>
<li>
<a href="#toc_16">RED方法</a>
</li>
<li>
<a href="#toc_17">USE vs. RED方法</a>
</li>
</ul>
</li>
<li>
<a href="#toc_18">在Kubernetes下的监控实践</a>
<ul>
<li>
<a href="#toc_19">性能指标</a>
</li>
<li>
<a href="#toc_20">服务健康状态监控</a>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">简介</h2>

<p>prometheus 是一个开源的系统监控和告警的工具包，其采用pull方式采集时间序列，通过http协议传输。由SoundCloud公司开发的。随着发展，越来越多公司和组织接受采用Prometheus，社区也十分活跃，他们便将它独立成开源项目，并且有公司来运作。google SRE的书内也曾提到跟他们BorgMon监控系统相似的实现是Prometheus。现在最常见的Kubernetes容器管理系统中，通常会搭配Prometheus进行监控。</p>

<h3 id="toc_1">Prometheus 的优点</h3>

<ul>
<li>非常少的外部依赖，安装使用超简单</li>
<li>已经有非常多的系统集成 例如：docker HAProxy Nginx JMX等等</li>
<li>服务自动化发现</li>
<li>直接集成到代码</li>
<li>设计思想是按照分布式、微服务架构来实现的</li>
</ul>

<h3 id="toc_2">Prometheus 的特性</h3>

<ul>
<li>自定义多维度的数据模型</li>
<li>非常高效的存储 平均一个采样数据占 ~3.5 bytes左右，320万的时间序列，每30秒采样，保持60天，消耗磁盘大概228G。</li>
<li>强大的查询语句</li>
<li>轻松实现数据可视化</li>
</ul>

<h3 id="toc_3">Prometheus 的相关组件</h3>

<ul>
<li>Prometheus 主服务,用来抓取和存储时序数据</li>
<li>client library 用来构造应用或 exporter 代码 (go,java,python,ruby)</li>
<li>push 网关可用来支持短连接任务</li>
<li>可视化的dashboard (两种选择,promdash 和 grafana.目前主流选择是 grafana.)</li>
<li>一些特殊需求的数据出口(用于HAProxy, StatsD, Graphite等服务)</li>
<li>实验性的报警管理端(alartmanager,单独进行报警汇总,分发,屏蔽等 )
promethues 的各个组件基本都是用 golang 编写,对编译和部署十分友好.并且没有特殊依赖.基本都是独立工作.</li>
</ul>

<h3 id="toc_4">Prometheus vs. Zabbix对比</h3>

<p>Zabbix 使用的是 C 和 PHP, Prometheus 使用 Golang, 整体而言 Prometheus 运行速度更快一点。<br/>
Zabbix 属于传统主机监控，主要用于物理主机、交换机、网络等监控，Prometheus 不仅适用主机监控，还适用于 Cloud、SaaS、Openstack、Container 监控。<br/>
Zabbix 在传统主机监控方面，有更丰富的插件。<br/>
Zabbix 可以在 WebGui 中配置很多事情，Prometheus 需要手动修改文件配置。</p>

<h2 id="toc_5">系统架构</h2>

<p><img src="media/15257584688763/15257586696383.jpg" alt=""/></p>

<pre><code>它的服务过程是这样的:
 Prometheus daemon 负责定时去目标上抓取 metrics(指标) 数据，每个抓取目标需要暴露一个http服务的接口给它定时抓取。
Prometheus支持通过配置文件、文本文件、zookeeper、Consul、DNS SRV lookup等方式指定抓取目标。
Alertmanager 是独立于Prometheus的一个组件，可以支持Prometheus的查询语句，提供十分灵活的报警方式。
Prometheus支持很多方式的图表可视化，例如十分精美的Grafana，自带的Promdash，以及自身提供的模版引擎等等，还提供HTTP API的查询方式，自定义所需要的输出。
PushGateway这个组件是支持Client主动推送 metrics 到PushGateway，而Prometheus只是定时去Gateway上抓取数据。

如果有使用过statsd的用户，则会觉得这十分相似，只是statsd是直接发送给服务器端，而Prometheus主要还是靠进程主动去抓取。
</code></pre>

<h2 id="toc_6">数据模型</h2>

<p>Prometheus 从根本上存储的所有数据都是时间序列数据（Time Serie Data，简称时序数据）。时序数据是具有时间戳的数据流，该数据流属于某个度量指标（Metric）和该度量指标下的多个标签（Label）。除了提供存储功能，Prometheus 还可以利用查询表达式来执行非常灵活和复杂的查询。</p>

<h3 id="toc_7">度量指标和标签</h3>

<p>每个时间序列（Time Serie，简称时序）由度量指标和一组标签键值对唯一确定。</p>

<p>度量指标名称描述了被监控系统的某个测量特征（比如 http_requests_total 表示 http 请求总数）。度量指标名称由 ASCII 字母、数字、下划线和冒号组成，须匹配正则表达式 [a-zA-Z_:][a-zA-Z0-9_:]*。</p>

<p>标签开启了 Prometheus 的多维数据模型。对于同一个度量指标，不同标签值组合会形成特定维度的时序。Prometheus 的查询语言可以通过度量指标和标签对时序数据进行过滤和聚合。改变任何度量指标上的任何标签值，都会形成新的时序。标签名称可以包含 ASCII 字母、数字和下划线，须匹配正则表达式 [a-zA-Z_][a-zA-Z0-9_]*，带有 _ 下划线的标签名称保留为内部使用。标签值可以包含任意 Unicode 字符，包括中文。</p>

<h3 id="toc_8">采样值（Sample）</h3>

<p>时序数据其实就是一系列采样值。每个采样值包括：</p>

<p>一个 64 位的浮点数值<br/>
一个精确到毫秒的时间戳</p>

<h3 id="toc_9">注解（Notation）</h3>

<p>一个注解由一个度量指标和一组标签键值对构成。形式如下：</p>

<p>[metric name]{[label name]=[label value], ...}<br/>
例如，度量指标为 api_http_requests_total，标签为 method=&quot;POST&quot;、handler=&quot;/messages&quot; 的注解表示如下：</p>

<p>api_http_requests_total{method=&quot;POST&quot;, handler=&quot;/messages&quot;}</p>

<h3 id="toc_10">度量指标类型</h3>

<p>Prometheus 里的度量指标有以下几种类型。</p>

<h3 id="toc_11">计数器（Counter）</h3>

<p>计数器是一种累计型的度量指标，它是一个只能递增的数值。计数器主要用于统计类似于服务请求数、任务完成数和错误出现次数这样的数据。</p>

<h3 id="toc_12">计量器（Gauge）</h3>

<p>计量器表示一个既可以增加, 又可以减少的度量指标值。计量器主要用于测量类似于温度、内存使用量这样的瞬时数据。</p>

<h3 id="toc_13">直方图（Histogram）</h3>

<p>直方图对观察结果（通常是请求持续时间或者响应大小这样的数据）进行采样，并在可配置的桶中对其进行统计。有以下几种方式来产生直方图（假设度量指标为 &lt;basename&gt;）：</p>

<p>按桶计数，相当于 <basename>_bucket{le=&quot;<upper inclusive bound>&quot;}<br/>
采样值总和，相当于 <basename>_sum<br/>
采样值总数，相当于 <basename>_count ，也等同于把所有采样值放到一个桶里来计数 <basename>_bucket{le=&quot;+Inf&quot;}</p>

<h3 id="toc_14">汇总（Summary）</h3>

<p>类似于直方图，汇总也对观察结果进行采样。除了可以统计采样值总和和总数，它还能够按分位数统计。有以下几种方式来产生汇总（假设度量指标为 &lt;basename&gt;）：</p>

<p>按分位数，也就是采样值小于该分位数的个数占总数的比例小于 φ，相当于 <basename>{quantile=&quot;&lt;φ&gt;&quot;}<br/>
采样值总和，相当于 <basename>_sum<br/>
采样值总数，相当于 <basename>_count<br/>
任务（Job）和实例（Instance）<br/>
在 Prometheus 里，可以从中抓取采样值的端点称为实例，为了性能扩展而复制出来的多个这样的实例形成了一个任务。</p>

<p>例如下面的 api-server 任务有四个相同的实例：</p>

<p>job: api-server<br/>
instance 1: 1.2.3.4:5670<br/>
instance 2: 1.2.3.4:5671<br/>
instance 3: 5.6.7.8:5670<br/>
instance 4: 5.6.7.8:5671<br/>
Prometheus 抓取完采样值后，会自动给采样值添加下面的标签和值：</p>

<p>job: 抓取所属任务。<br/>
instance: 抓取来源实例<br/>
另外每次抓取时，Prometheus 还会自动在以下时序里插入采样值：</p>

<p>up{job=&quot;[job-name]&quot;, instance=&quot;instance-id&quot;}：采样值为 1 表示实例健康，否则为不健康<br/>
scrape_duration_seconds{job=&quot;[job-name]&quot;, instance=&quot;[instance-id]&quot;}：采样值为本次抓取消耗时间<br/>
scrape_samples_post_metric_relabeling{job=&quot;<job-name>&quot;, instance=&quot;<instance-id>&quot;}：采样值为重新打标签后的采样值个数<br/>
scrape_samples_scraped{job=&quot;<job-name>&quot;, instance=&quot;<instance-id>&quot;}：采样值为本次抓取到的采样值个数</p>

<h2 id="toc_15">监控的关键指标</h2>

<p>在搭建Prometheus监控时，确定需要收集的指标类型十分重要，这些指标和应用程序相关。选择的指标可以简化故障发生时排除故障的流程，并且还可以在服务和基础设施上保持很高的稳定性。为帮助理解instrument的重要性，我们定义了一个称之为RED方法的系统。</p>

<h3 id="toc_16">RED方法</h3>

<p>RED方法遵循Four Golden Signals中提及的原则，聚焦于检测最终用户在使用web服务时关心的东西。</p>

<p>在RED方法中，我们通过监控三项关键指标来管理架构中的每个微服务：</p>

<p>（Request）Rate – 你的服务所服务的每秒的请求数<br/>
（Request）Errors – 每秒失败的请求数<br/>
（Request）Duration – 每个请求所花费的时间，用时间间隔表示</p>

<p>RED方法希望由Rate、Errors、Duration三项指标涵盖最典型的Web服务问题。同时这些指标还能够反映出请求的错误率。通过这三项指标，我们就能监测到通常情况下会影响客户体验的问题。</p>

<p>如果想要获得更细节的信息，还需要用到Saturation指标。Saturation指标用在USE（Utilization Saturation and Errors）方法中，它指的是一种带有额外作业的资源，而该资源不能够提供服务，因此必须添加到队列中以备后续处理。</p>

<h3 id="toc_17">USE vs. RED方法</h3>

<p>对比两种方法，USE方法更侧重于监控的性能，并以此为出发点寻找影响性能问题的根本原因以及其他系统的瓶颈。</p>

<p>在理想状态下，我们可以在监控应用程序时同时使用USE和RED方法。<br/>
为什么要对每个服务衡量相同的指标<br/>
从监控的角度来看，如果能处理好每项服务，你的运营团队就可以在此基础上继续扩展服务。</p>

<p>扩展性对运营团队意味着什么？<br/>
我们从这个角度看待问题，一个团队可以支持多少个服务。在理想状态下，一个团队可以支持的服务数量和团队规模无关，而取决于其他因素，比如SLA协议的响应类型以及是否需要全天候覆盖等等。</p>

<p>如何将可支持的服务数量与团队规模去藕化？<br/>
办法是让每一个服务都变得一样。这既减少了团队针对特定的服务进行培训的数量，还减少了在高压事件响应场景或者所谓“认知负载”这些针对特定服务的特殊情况发生时，呼叫者需要记录的内容。</p>

<p>容量规划：<br/>
考虑QPS（每秒查询次数）和延迟</p>

<p>自动化任务以及发出警报：<br/>
RED方法的优点在于它可以帮助你考虑如何在仪表板中显示信息。通过这三个指标，你可以对仪表板的布局进行调整，让它更易于阅读，并在问题发生时发出警报。例如，一个布局可能意味着 --- 每个服务都有一个不同的Weave Cloud记事本，包含了PromQL查询的请求&amp;错误，以及每个服务的延迟。</p>

<p>毫无疑问，如果把所有的服务都视为一样的，那么将会更加易于自动化执行重复任务。</p>

<p>PromQL查询<br/>
<img src="media/15257584688763/15262946692850.jpg" alt=""/></p>

<p>在Weave Cloud上监控RED方法中的指标<br/>
<img src="media/15257584688763/15262946802946.jpg" alt=""/></p>

<p>局限性</p>

<p>事实上，这种方法（RED）仅适用于请求驱动的服务——比如，它在处理面向批处理的服务或者流服务时会发生错误。对于请求驱动它也不是完全适用，当需要监控其他东西——比如主机CPU&amp;内存或者缓存资源时，USE方法表现的更好。</p>

<h2 id="toc_18">在Kubernetes下的监控实践</h2>

<h3 id="toc_19">性能指标</h3>

<p>容器相关的性能指标数据(如：cpu, memory, filesystem；<br/>
Pod相关的性能指标数据;<br/>
主机节点相关的性能指标数据;</p>

<h3 id="toc_20">服务健康状态监控</h3>

<p>Deployment相关的健康状态（health or unhealth）;<br/>
Pod的健康状态；<br/>
主机Node节点的健康状态</p>

<p>一直以来 Prometheus 被吐槽最多的就是 HA 和集群方案:采用 remote_read 实现 Prometheus 数据的读写分离的集群方案</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[监控迁移过程注意事项整理]]></title>
    <link href="www.anhaoker.com/15253278795397.html"/>
    <updated>2018-05-03T14:11:19+08:00</updated>
    <id>www.anhaoker.com/15253278795397.html</id>
    <content type="html"><![CDATA[
<p>注意：中断业务操作-仅限切换IP（111——》45，58——》111）</p>

<h2 id="toc_0">1、从原111迁移数据库（预计会丢失期间迁移的监控数据）</h2>

<p>grant ALL PRIVILEGES on <em>.</em> to &#39;backupdata&#39;@&#39;localhost&#39; identified by &#39;6&amp;$ikRgviuKyvVm2&#39;;</p>

<p>create user &#39;repler&#39;@&#39;172.18.100.58&#39; identified by &#39;Repler@bdyg2017&#39;;<br/>
grant replication slave on <em>.</em> to repler@&#39;172.18.100.58&#39;;</p>

<p>time innobackupex  --defaults-file=/etc/my3306.cnf  --user=backupdata --password=&#39;6&amp;$ikRgviuKyvVm2&#39;  --slave-info --no-timestamp --stream=tar /data/backup/ |gzip &gt; /data/backup/all-3306.<code>date -I</code>.tar.gz</p>

<h2 id="toc_1">2、恢复数据到原58</h2>

<p>grant ALL PRIVILEGES on <em>.</em> to &#39;backupdata&#39;@&#39;localhost&#39;;</p>

<p>rm -rf /data/mysql/3306/data/**<br/>
innobackupex --defaults-file=/etc/my3306.cnf --port=3306 --apply-log /data/backup/all-3306.<code>date -I</code><br/>
innobackupex --defaults-file=/etc/my3306.cnf --port=3306 --copy-back /data/backup/all-3306.<code>date -I</code><br/>
chown -R mysql.mysql /data/mysql/3306/data/<br/>
/etc/init.d/mysqld_3306 restart</p>

<h2 id="toc_2">3、切换IP</h2>

<p>先将111 切换至45IP<br/>
将原58IP 切换至111</p>

<h2 id="toc_3">4、验证</h2>

<p>nginx<br/>
zabbix<br/>
天兔</p>

<h2 id="toc_4">5、故障排查</h2>

<p>迁移后问题梳理——更换ip 尽可能重启</p>

<h3 id="toc_5">1、网络设备出图</h3>

<p>开启防火墙</p>

<h3 id="toc_6">2、IO出图</h3>

<pre><code>/usr/local/zabbix/bin/zabbix_get -s 172.18.100.62 -p10050 -k &quot;disk.status[vda,util]&quot; 

cd /usr/local/src;wget http://bjqw-dl.bjtuling.com:8180/zabbix/init_scripts/init_zabbix_iostat_status.sh;sh init_zabbix_iostat_status.sh


vi /etc/zabbix/zabbix_scripts/disk_status.sh

#/bin/sh
device=$1
item=$2

/usr/bin/iostat -dxkt 1 2 &gt; /tmp/iostat_output 2&gt;/dev/null

case $item in

rrqm)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot;|tail -1|awk &#39;{print $2}&#39;
;;

wrqm)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot;|tail -1|awk &#39;{print $3}&#39;
;;

rps)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot;|tail -1|awk &#39;{print $4}&#39;
;;

wps)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $5}&#39;
;;

rKBps)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $6}&#39;
;;

wKBps)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $7}&#39;
;;

avgrq-sz)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $8}&#39;
;;

avgqu-sz)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $9}&#39;
;;

await)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $10}&#39;
;;

r_await)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $11}&#39;
;;

w_await)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $12}&#39;
;;

svctm)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $13}&#39;
;;

util)
/usr/bin/tail -n20 /tmp/iostat_output |grep &quot;\b$device\b&quot; |tail -1|awk &#39;{print $14}&#39;
;;
esac




vim /etc/zabbix/zabbix_agentd.conf.d/userparameter_iostat.conf

UserParameter=disk.status[*],/bin/bash /etc/zabbix/zabbix_scripts/disk_status.sh $1 $2

/etc/init.d/zabbix_agentd restart

</code></pre>

<h3 id="toc_7">3、tomcat</h3>

<pre><code>servers端安装 jdk,
并确认安装时开启 --enable-java

cd /usr/local/src;wget http://bjqw-dl.bjtuling.com:8180/zabbix/init_scripts/init_zabbix_tomcat_multi_status.sh;sh init_zabbix_tomcat_multi_status.sh

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[zabbix3.2升级到3.4]]></title>
    <link href="www.anhaoker.com/15246459775922.html"/>
    <updated>2018-04-25T16:46:17+08:00</updated>
    <id>www.anhaoker.com/15246459775922.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0"></a>
</li>
</ul>


<h2 id="toc_0"></h2>

<p>zabbix官网：<a href="http://www.zabbix.com">http://www.zabbix.com</a><br/>
zabbix下载地址：<a href="http://www.zabbix.com/download">http://www.zabbix.com/download</a><br/>
zabbix下载地址：<a href="https://repo.zabbix.com/zabbix/3.2/rhel/7/x86_64/">https://repo.zabbix.com/zabbix/3.2/rhel/7/x86_64/</a><br/>
zabbix监控模板：<a href="https://share.zabbix.com/search-by/tags?value=netkiller">https://share.zabbix.com/search-by/tags?value=netkiller</a></p>

<p>一、系统环境</p>

<p>cat /etc/redhat-release </p>

<p>原有zabbix版本:Zabbix 3.2.7<br/>
升级zabbix版本:Zabbix 3.4.1</p>

<p>二、检查及卸载当前zabbix版本</p>

<p>1、升级准备<br/>
停止Zabbix server<br/>
/etc/init.d/zabbix_server stop</p>

<p>2、备份现有的Zabbix数据库<br/>
mysqldump -uzabbix -pzabbix zabbix &gt; zabbix20171021.sql</p>

<p>3、备份配置文件，PHP文件和Zabbix二进制文件</p>

<p>mv /etc/zabbix /etc/zabbix32<br/>
mv /data/www/zabbix /data/www/zabbix32<br/>
mv /usr/local/zabbix /usr/local/zabbix32</p>

<p>三、编译安装新版本</p>

<p>1、下载源码包</p>

<pre><code>wget https://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/3.4.10/zabbix-3.4.10.tar.gz
tar zxf zabbix-3.4.10.tar.gz
cd zabbix-3.4.10
</code></pre>

<p>2、编译</p>

<pre><code>./configure --prefix=/usr/local/zabbix-3.4.10 --sysconfdir=/etc/zabbix --enable-server --enable-proxy --enable-agent --enable-ipv6 --with-mysql=/usr/local/mysql-5.7.20/bin/mysql_config --with-net-snmp --with-libxml2 --with-libcurl  --with-openssl --with-openipmi --with-unixodbc --with-ldap --with-ssh2 --enable-java
make &amp;&amp; make install
ln -s /usr/local/zabbix-3.4.10 /usr/local/zabbix
</code></pre>

<p>3、修改配置文件</p>

<pre><code>grep -vE &quot;^#|^$&quot; /etc/zabbix/zabbix_server.conf  
 
LogFile=/var/log/zabbix/zabbix_server.log
DBName=zabbix
DBUser=zabbix
DBPassword=Zabbix@2016
DBSocket=/tmp/mysql3331.sock
DBPort=3331
Timeout=4
LogSlowQueries=3000
StartPollers=160
StartTrappers=20
StartPingers=100
StartDiscoverers=120
MaxHousekeeperDelete=5000
CacheSize=1024M
StartDBSyncers=16
HistoryCacheSize=1024M
TrendCacheSize=1024M
AlertScriptsPath=/etc/zabbix/alertscripts
FpingLocation=/usr/sbin/fping
LogSlowQueries=1000

HousekeepingFrequency=12
MaxHousekeeperDelete=1000000

#java jmx
JavaGateway=10.100.4.214
JavaGatewayPort=10052
StartJavaPollers=20
</code></pre>

<p>4、替换web代码</p>

<pre><code>cd /usr/local/src/zabbix-3.4.10/frontends/
cp -r php /data/www/zabbix
chown -R nobody.nobody /data/www/
</code></pre>

<p>5、启动服务</p>

<pre><code>/etc/init.d/nginx reload
/etc/init.d/zabbix_server start
</code></pre>

<p>6、升级监测 </p>

<pre><code>tail -fn1 /var/log/zabbix/zabbix_server.log
</code></pre>

<p>7、配置WEB信息 </p>

<p>8、升级之前功能 </p>

<pre><code>#报警相关脚本及监控脚本
\cp -r /etc/zabbix32/*scripts /etc/zabbix/
</code></pre>

<pre><code>#安装java_gateway
rpm -i http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpm
 yum -y install zabbix-java-gateway
systemctl restart zabbix-java-gateway.service
systemctl status zabbix-java-gateway.service 

客户端：添加tomact中JMX的参数：在文件开头配置即可。
vim $tomcat/bin/catalina.sh 
CATALINA_OPTS=&quot;$CATALINA_OPTS
        -Dcom.sun.management.jmxremote
        -Dcom.sun.management.jmxremote.port=8081    # JMX端口，默认12345
        -Dcom.sun.management.jmxremote.authenticate=false
        -Dcom.sun.management.jmxremote.ssl=false
        -Djava.rmi.server.hostname=本机IP&quot; 
</code></pre>

]]></content>
  </entry>
  
</feed>
