<!DOCTYPE html>
<html>

<head>
    <title>
         3.1.2 第2章 SQL语句优化 - 安红雷 - An Honglei ’s Blog 
    </title>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="从心开始">

    <link rel="stylesheet" type="text/css" href="asset/yue.css">
    <link rel="stylesheet" type="text/css" href="asset/main.css">
    <link rel="stylesheet" type="text/css" href="asset/tomorrow.css">

    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="An Honglei ’s Blog">

    <script src="asset/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
</head>

<body>
    <header class="yue site-header">
        <div class="wrapper">
            <a class="site-title" href="index.html">An Honglei ’s Blog</a>
            <nav class="site-nav">
                <a href="#" class="menu-icon">
                    
                    <svg viewBox="0 0 18 15">
                        <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"
                        />
                        <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"
                        />
                        <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"
                        />
                    </svg>

                </a>
                <div class="trigger">
                    
                        <a class="page-link" href="index.html">Home</a>
                    
                        <a class="page-link" href="archives.html">Archives</a>
                    
                        <a class="page-link" href="/docker">Docker</a>
                    
                </div>
            </nav>
        </div>
    </header>
</body>

</html> <script async defer src="//hypothes.is/embed.js"></script>
<div class="page-content yue">
    <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
            <header class="post-header">
                <h1 class="post-title" itemprop="name headline">3.1.2 第2章 SQL语句优化 - 安红雷</h1>
                <div class="post-description">
                    
                        <p>慕课网视频地址：<a href="https://www.imooc.com/learn/194">https://www.imooc.com/learn/194</a><br/>
课程要点：</p>

<h2 id="toc_0">1. 演示数据库我会调配资源提供给大家使用；</h2>

<h3 id="toc_1">下载sakila数据库</h3>

<pre><code>http://dev.mysql.com/doc/index-other.html
tar xf sakila-db.tar
source /data/backup/sakila-db/sakila-schema.sql
source /data/backup/sakila-db/sakila-data.sql;

进入示例：
root@localhost:(none) 06:39:23 &gt;use sakila;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
root@localhost:sakila 06:39:33 &gt;show tables;
+----------------------------+
| Tables_in_sakila           |
+----------------------------+
| actor                      |
| actor_info                 |
| address                    |
| category                   |
| city                       |
| country                    |
| customer                   |
| customer_list              |
| film                       |
| film_actor                 |
| film_category              |
| film_list                  |
| film_text                  |
| inventory                  |
| language                   |
| nicer_but_slower_film_list |
| payment                    |
| rental                     |
| sales_by_film_category     |
| sales_by_store             |
| staff                      |
| staff_list                 |
| store                      |
+----------------------------+
23 rows in set (0.00 sec)
</code></pre>

<h3 id="toc_2">2. SQL语句的优化</h3>

<h4 id="toc_3">第一步：哪些SQL及索引是需要优化的——如何发现有问题的SQL</h4>

<p>主要使用Mysql慢日志对效率有问题的SQL进行监控</p>

<h4 id="toc_4">开启及设置慢查询日志——针对mysql实例非数据库</h4>

<pre><code>root@localhost:sakila 06:56:56 &gt;show variables like &#39;slow_query_log&#39;;
+----------------+-------+
| Variable_name  | Value |
+----------------+-------+
| slow_query_log | ON    |
+----------------+-------+
1 row in set (0.00 sec)

root@localhost:sakila 06:58:05 &gt;show variables like &#39;slow_query_log_file&#39;;
+---------------------+--------------------------------+
| Variable_name       | Value                          |
+---------------------+--------------------------------+
| slow_query_log_file | /data/mysql/3306/logs/slow.log |
+---------------------+--------------------------------+
1 row in set (0.00 sec)

**开启记录没有使用索引的SQL**
root@localhost:sakila 06:58:41 &gt;set global log_queries_not_using_indexes=on;
Query OK, 0 rows affected (0.00 sec)

**慢查询日志设置的记录超时时间**
root@localhost:sakila 07:01:53 &gt;set global long_query_time=1;
Query OK, 0 rows affected (0.00 sec)
</code></pre>

<h4 id="toc_5">查询语句的慢查询结构信息</h4>

<pre><code>root@localhost:sakila 07:02:17 &gt;select * from store limit 10;
+----------+------------------+------------+---------------------+
| store_id | manager_staff_id | address_id | last_update         |
+----------+------------------+------------+---------------------+
|        1 |                1 |          1 | 2006-02-15 04:57:12 |
|        2 |                2 |          2 | 2006-02-15 04:57:12 |
+----------+------------------+------------+---------------------+
2 rows in set (0.00 sec)

root@localhost:sakila 07:18:09 &gt;show variables like &#39;slow%&#39;;
+---------------------+--------------------------------+
| Variable_name       | Value                          |
+---------------------+--------------------------------+
| slow_launch_time    | 2                              |
| slow_query_log      | ON                             |
| slow_query_log_file | /data/mysql/3306/logs/slow.log |
+---------------------+--------------------------------+
3 rows in set (0.00 sec)
</code></pre>

<pre><code>root@anhonglei-test-bjqw:~ # tail -fn10 /data/mysql/3306/logs/slow.log
# User@Host: root[root] @ localhost []  Id:     4
# Query_time: 3.012571  Lock_time: 0.000523 Rows_sent: 0  Rows_examined: 0
SET timestamp=1513930484;
GRANT ALL PRIVILEGES ON *.* TO &#39;admin&#39;@&#39;localhost&#39; IDENTIFIED WITH &#39;mysql_native_password&#39; AS &#39;*CC5F1D1D66012B7EE904E3C06451B244778D4C31&#39;;

执行时间
# Time: 2018-01-13T19:18:09.233197+08:00

执行主机的信息
# User@Host: root[root] @ localhost []  Id:    21

SQL语句执行的信息：查询执行时间，锁定时间，发送的行数，扫描的行数
# Query_time: 0.000597  Lock_time: 0.000207 Rows_sent: 2  Rows_examined: 2
use sakila;

SQL执行的时间：时间戳形式
SET timestamp=1515842289;

执行的SQL内容
select * from store limit 10;


</code></pre>

<h4 id="toc_6">分析慢查询日志：使用工具批量分析慢查询日志得出结果</h4>

<h5 id="toc_7">Mysql自带工具：mysqldumpslow</h5>

<pre><code>root@anhonglei-test-bjqw:~ # mysqldumpslow --help
Usage: mysqldumpslow [ OPTS... ] [ LOGS... ]

Parse and summarize the MySQL slow query log. Options are

  --verbose    verbose
  --debug      debug
  --help       write this text to standard output

  -v           verbose
  -d           debug
  -s ORDER     what to sort by (al, at, ar, c, l, r, t), &#39;at&#39; is default
                al: average lock time
                ar: average rows sent
                at: average query time
                 c: count
                 l: lock time
                 r: rows sent
                 t: query time  
  -r           reverse the sort order (largest last instead of first)
  -t NUM       just show the top n queries
  -a           don&#39;t abstract all numbers to N and strings to &#39;S&#39;
  -n NUM       abstract numbers with at least n digits within names
  -g PATTERN   grep: only consider stmts that include this string
  -h HOSTNAME  hostname of db server for *-slow.log filename (can be wildcard),
               default is &#39;*&#39;, i.e. match all
  -i NAME      name of server instance (if using mysql.server startup script)
  -l           don&#39;t subtract lock time from total time
</code></pre>

<pre><code>root@anhonglei-test-bjqw:~ # mysqldumpslow -t 1 /data/mysql/3306/logs/slow.log

Reading mysql slow query log from /data/mysql/3306/logs/slow.log

执行次数，执行时间，锁时间，发送的行数，执行主机信息，
Count: 1  Time=3.01s (3s)  Lock=0.00s (0s)  Rows=0.0 (0), root[root]@localhost

  执行的语句
  GRANT ALL PRIVILEGES ON *.* TO &#39;S&#39;@&#39;S&#39; IDENTIFIED WITH &#39;S&#39; AS &#39;S&#39;
</code></pre>

<h5 id="toc_8">常用分析工具：pt-query-digest</h5>

<p>pt-query-digest是用于分析mysql慢查询的一个工具，它也可以分析binlog、General log、slowlog，也可以通过SHOWPROCESSLIST或者通过tcpdump抓取的MySQL协议数据来进行分析。可以把分析结果输出到文件中，分析过程是先对查询语句的条件进行参数化，然后对参数化以后的查询进行分组统计，统计出各查询的执行时间、次数、占比等，可以借助分析结果找出问题进行优化。</p>

<p>1:安装于Perl相关的模块<br/>
 yum -y install perl perl-IO-Socket-SSL perl-DBD-MySQL perl-Time-HiRes<br/><br/>
 2:下载和安装percona toolkit的包<br/>
wget <a href="https://www.percona.com/downloads/percona-toolkit/2.2.16/RPM/percona-toolkit-2.2.16-1.noarch.rpm">https://www.percona.com/downloads/percona-toolkit/2.2.16/RPM/percona-toolkit-2.2.16-1.noarch.rpm</a> &amp;&amp; yum localinstall -y  percona-toolkit-2.2.16-1.noarch.rpm</p>

<pre><code>root@anhonglei-test-bjqw:~ # pt-query-digest --help
pt-query-digest analyzes MySQL queries from slow, general, and binary log files.
It can also analyze queries from C&lt;SHOW PROCESSLIST&gt; and MySQL protocol data
from tcpdump.  By default, queries are grouped by fingerprint and reported in
descending order of query time (i.e. the slowest queries first).  If no C&lt;FILES&gt;
are given, the tool reads C&lt;STDIN&gt;.  The optional C&lt;DSN&gt; is used for certain
options like L&lt;&quot;--since&quot;&gt; and L&lt;&quot;--until&quot;&gt;.  For more details, please use the
--help option, or try &#39;perldoc /bin/pt-query-digest&#39; for complete documentation.

Usage: pt-query-digest [OPTIONS] [FILES] [DSN]

Options:

  --ask-pass                  Prompt for a password when connecting to MySQL
  --attribute-aliases=a       List of attribute|alias,etc (default db|Schema)
  --attribute-value-limit=i   A sanity limit for attribute values (default
                              4294967296)
  --charset=s             -A  Default character set
  --config=A                  Read this comma-separated list of config files;
                              if specified, this must be the first option on
                              the command line
  --[no]continue-on-error     Continue parsing even if there is an error (
                              default yes)
  --[no]create-history-table  Create the --history table if it does not exist (
                              default yes)
  --[no]create-review-table   Create the --review table if it does not exist (
                              default yes)
  --daemonize                 Fork to the background and detach from the shell
  --database=s            -D  Connect to this database
  --defaults-file=s       -F  Only read mysql options from the given file
  --embedded-attributes=a     Two Perl regex patterns to capture pseudo-
                              attributes embedded in queries
  --expected-range=a          Explain items when there are more or fewer than
                              expected (default 5,10)
  --explain=d                 Run EXPLAIN for the sample query with this DSN
                              and print results
  --filter=s                  Discard events for which this Perl code doesn&#39;t
                              return true
  --group-by=A                Which attribute of the events to group by (
                              default fingerprint)
  --help                      Show help and exit
  --history=d                 Save metrics for each query class in the given
                              table. pt-query-digest saves query metrics (query
                              time, lock time, etc.) to this table so you can
                              see how query classes change over time
  --host=s                -h  Connect to host
  --ignore-attributes=a       Do not aggregate these attributes (default arg,
                              cmd, insert_id, ip, port, Thread_id, timestamp,
                              exptime, flags, key, res, val, server_id, offset,
                              end_log_pos, Xid)
  --inherit-attributes=a      If missing, inherit these attributes from the
                              last event that had them (default db,ts)
  --interval=f                How frequently to poll the processlist, in
                              seconds (default .1)
  --iterations=i              How many times to iterate through the collect-and-
                              report cycle (default 1)
  --limit=A                   Limit output to the given percentage or count (
                              default 95%:20)
  --log=s                     Print all output to this file when daemonized
  --order-by=A                Sort events by this attribute and aggregate
                              function (default Query_time:sum)
  --outliers=a                Report outliers by attribute:percentile:count (
                              default Query_time:1:10)
  --output=s                  How to format and print the query analysis
                              results (default report)
  --password=s            -p  Password to use when connecting
  --pid=s                     Create the given PID file
  --port=i                -P  Port number to use for connection
  --processlist=d             Poll this DSN&#39;s processlist for queries, with --
                              interval sleep between
  --progress=a                Print progress reports to STDERR (default time,30)
  --read-timeout=m            Wait this long for an event from the input; 0 to
                              wait forever (default 0).  Optional suffix s=
                              seconds, m=minutes, h=hours, d=days; if no
                              suffix, s is used.
  --[no]report                Print query analysis reports for each --group-by
                              attribute (default yes)
  --report-all                Report all queries, even ones that have been
                              reviewed
  --report-format=A           Print these sections of the query analysis
                              report (default rusage,date,hostname,files,header,
                              profile,query_report,prepared)
  --report-histogram=s        Chart the distribution of this attribute&#39;s
                              values (default Query_time)
  --resume=s                  If specified, the tool writes the last file
                              offset, if there is one, to the given filename
  --review=d                  Save query classes for later review, and don&#39;t
                              report already reviewed classes
  --run-time=m                How long to run for each --iterations.  Optional
                              suffix s=seconds, m=minutes, h=hours, d=days; if
                              no suffix, s is used.
  --run-time-mode=s           Set what the value of --run-time operates on (
                              default clock)
  --sample=i                  Filter out all but the first N occurrences of
                              each query
  --set-vars=A                Set the MySQL variables in this comma-separated
                              list of variable=value pairs
  --show-all=H                Show all values for these attributes
  --since=s                   Parse only queries newer than this value (parse
                              queries since this date)
  --socket=s              -S  Socket file to use for connection
  --timeline                  Show a timeline of events
  --type=A                    The type of input to parse (default slowlog)
  --until=s                   Parse only queries older than this value (parse
                              queries until this date)
  --user=s                -u  User for login if not current user
  --variations=A              Report the number of variations in these
                              attributes&#39; values
  --version                   Show version and exit
  --[no]version-check         Check for the latest version of Percona Toolkit,
                              MySQL, and other programs (default yes)
  --watch-server=s            This option tells pt-query-digest which server IP
                              address and port (like &quot;10.0.0.1:3306&quot;) to watch
                              when parsing tcpdump (for --type tcpdump); all
                              other servers are ignored

Option types: s=string, i=integer, f=float, h/H/a/A=comma-separated list, d=DSN, z=size, m=time

Rules:

  This tool accepts additional command-line arguments. Refer to the SYNOPSIS and usage information for details.

DSN syntax is key=value[,key=value...]  Allowable DSN keys:

  KEY  COPY  MEANING
  ===  ====  =============================================
  A    yes   Default character set
  D    yes   Default database to use when connecting to MySQL
  F    yes   Only read default options from the given file
  P    yes   Port number to use for connection
  S    yes   Socket file to use for connection
  h    yes   Connect to host
  p    yes   Password to use when connecting
  t    no    The --review or --history table
  u    yes   User for login if not current user

  If the DSN is a bareword, the word is treated as the &#39;h&#39; key.

Options and values after processing arguments:

  --ask-pass                  FALSE
  --attribute-aliases         db|Schema
  --attribute-value-limit     4294967296
  --charset                   (No value)
  --config                    /etc/percona-toolkit/percona-toolkit.conf,/etc/percona-toolkit/pt-query-digest.conf,/root/.percona-toolkit.conf,/root/.pt-query-digest.conf
  --continue-on-error         TRUE
  --create-history-table      TRUE
  --create-review-table       TRUE
  --daemonize                 FALSE
  --database                  (No value)
  --defaults-file             (No value)
  --embedded-attributes       (No value)
  --expected-range            5,10
  --explain                   (No value)
  --filter                    (No value)
  --group-by                  fingerprint
  --help                      TRUE
  --history                   (No value)
  --host                      (No value)
  --ignore-attributes         arg,cmd,insert_id,ip,port,Thread_id,timestamp,exptime,flags,key,res,val,server_id,offset,end_log_pos,Xid
  --inherit-attributes        db,ts
  --interval                  .1
  --iterations                1
  --limit                     95%:20
  --log                       (No value)
  --order-by                  Query_time:sum
  --outliers                  Query_time:1:10
  --output                    report
  --password                  (No value)
  --pid                       (No value)
  --port                      (No value)
  --processlist               (No value)
  --progress                  time,30
  --read-timeout              0
  --report                    TRUE
  --report-all                FALSE
  --report-format             rusage,date,hostname,files,header,profile,query_report,prepared
  --report-histogram          Query_time
  --resume                    (No value)
  --review                    (No value)
  --run-time                  (No value)
  --run-time-mode             clock
  --sample                    (No value)
  --set-vars                  
  --show-all                  
  --since                     (No value)
  --socket                    (No value)
  --timeline                  FALSE
  --type                      slowlog
  --until                     (No value)
  --user                      (No value)
  --variations                
  --version                   FALSE
  --version-check             TRUE
  --watch-server              (No value)
</code></pre>

<pre><code>root@anhonglei-test-bjqw:~ # pt-query-digest /data/mysql/3306/logs/slow.log &gt; slow_log.report
*******************************************************************
 Using the default of SSL_verify_mode of SSL_VERIFY_NONE for client
 is deprecated! Please set SSL_verify_mode to SSL_VERIFY_PEER
 together with SSL_ca_file|SSL_ca_path for verification.
 If you really don&#39;t want to verify the certificate and keep the
 connection open to Man-In-The-Middle attacks please set
 SSL_verify_mode explicitly to SSL_VERIFY_NONE in your application.
*******************************************************************
  at /bin/pt-query-digest line 11847.
*******************************************************************
 Using the default of SSL_verify_mode of SSL_VERIFY_NONE for client
 is deprecated! Please set SSL_verify_mode to SSL_VERIFY_PEER
 together with SSL_ca_file|SSL_ca_path for verification.
 If you really don&#39;t want to verify the certificate and keep the
 connection open to Man-In-The-Middle attacks please set
 SSL_verify_mode explicitly to SSL_VERIFY_NONE in your application.
*******************************************************************
  at /bin/pt-query-digest line 11847.
  
  ##分析结果信息：
  root@anhonglei-test-bjqw:~ # cat slow_log.report 

# A software update is available:
#   * The current version for Percona::Toolkit is 3.0.5

##头部信息：
#默认95%的SQL总耗时：用户时间，系统时间 ，。。。
# 310ms user time, 40ms system time, 27.80M rss, 236.60M vsz
# Current date: Sat Jan 13 21:58:05 2018
# Hostname: anhonglei-test-bjqw.bd-yg.com
# Files: /data/mysql/3306/logs/slow.log

#包含的SQL总数，不同的SQL个数，
# Overall: 2 total, 2 unique, 0 QPS, 0x concurrency ______________________

#各结果耗时      总计    最小    最大  平均      包含数量
# Attribute          total     min     max     avg     95%  stddev  median
# ============     ======= ======= ======= ======= ======= ======= =======
# Exec time             3s   597us      3s      2s      3s      2s      2s
# Lock time          730us   207us   523us   365us   523us   223us   365us
# Rows sent              2       0       2       1       2    1.41       1
# Rows examine           2       0       2       1       2    1.41       1
# Query size           165      28     137   82.50     137   77.07   82.50
## 对比Rows sent 和Rows examine 数据差距是否很大，判断索引是否有效。


##相关表的执行信息：
# Profile
# Rank Query ID           Response time Calls R/Call V/M   Item
# ==== ================== ============= ===== ====== ===== =========

#   表名 ，    响应时间   单SQL占比    执行次数   读取行数    相关具体操作
#    1 0x80591928D0217D4E 3.0126 100.0%     1 3.0126  0.00 
# MISC 0xMISC              0.0006  0.0%     1 0.0006   0.0 &lt;1 ITEMS&gt;


##单条SQL的具体信息：
# Query 1: 0 QPS, 0x concurrency, ID 0x80591928D0217D4E at byte 0 ________
# This item is included in the report because it matches --limit.
# Scores: V/M = 0.00

#具体信息   总时间百分比  总数 最小  最大  。。。
# Attribute    pct   total     min     max     avg     95%  stddev  median
# ============ === ======= ======= ======= ======= ======= ======= =======
# Count         50       1
# Exec time     99      3s      3s      3s      3s      3s       0      3s
# Lock time     71   523us   523us   523us   523us   523us       0   523us
# Rows sent      0       0       0       0       0       0       0       0
# Rows examine   0       0       0       0       0       0       0       0
# Query size    83     137     137     137     137     137       0     137
# String:
# Hosts        localhost
# Time         2017-12-22T16:14:44.780690+08:00
# Users        root
# Query_time distribution
#   1us
#  10us
# 100us
#   1ms
#  10ms
# 100ms
#    1s  ################################################################
#  10s+

#具体的语句内容
GRANT ALL PRIVILEGES ON *.* TO &#39;admin&#39;@&#39;localhost&#39; IDENTIFIED WITH &#39;mysql_native_password&#39; AS &#39;*CC5F1D1D66012B7EE904E3C06451B244778D4C31&#39;\G
  
</code></pre>

<h5 id="toc_9">用法示例</h5>

<pre><code>(1)直接分析慢查询文件:
pt-query-digest  slow.log &gt; slow_report.log

(2)分析最近12小时内的查询：

pt-query-digest  --since=12h  slow.log &gt; slow_report2.log

(3)分析指定时间范围内的查询：

pt-query-digest slow.log --since &#39;2014-04-17 09:30:00&#39; --until &#39;2014-04-17 10:00:00&#39;&gt; &gt; slow_report3.log

(4)分析指含有select语句的慢查询
pt-query-digest--filter &#39;$event-&gt;{fingerprint} =~ m/^select/i&#39; slow.log&gt; slow_report4.log

(5) 针对某个用户的慢查询
pt-query-digest--filter &#39;($event-&gt;{user} || &quot;&quot;) =~ m/^root/i&#39; slow.log&gt; slow_report5.log

(6) 查询所有所有的全表扫描或full join的慢查询
pt-query-digest--filter &#39;(($event-&gt;{Full_scan} || &quot;&quot;) eq &quot;yes&quot;) ||(($event-&gt;{Full_join} || &quot;&quot;) eq &quot;yes&quot;)&#39; slow.log&gt; slow_report6.log

(7)把查询保存到query_review表
pt-query-digest  --user=root –password=abc123 --review  h=localhost,D=test,t=query_review--create-review-table  slow.log

(8)把查询保存到query_history表
pt-query-digest  --user=root –password=abc123 --review  h=localhost,D=test,t=query_ history--create-review-table  slow.log_20140401
pt-query-digest  --user=root –password=abc123--review  h=localhost,D=test,t=query_history--create-review-table  slow.log_20140402

(9)通过tcpdump抓取mysql的tcp协议数据，然后再分析
tcpdump -s 65535 -x -nn -q -tttt -i any -c 1000 port 3306 &gt; mysql.tcp.txt
pt-query-digest --type tcpdump mysql.tcp.txt&gt; slow_report9.log

(10)分析binlog
mysqlbinlog mysql-bin.000093 &gt; mysql-bin000093.sql
pt-query-digest  --type=binlog  mysql-bin000093.sql &gt; slow_report10.log

(11)分析general log
pt-query-digest  --type=genlog  localhost.log &gt; slow_report11.log


官方文档：http://www.percona.com/doc/percona-toolkit/2.2/pt-query-digest.html
</code></pre>

<h2 id="toc_10">第二步 分析慢查询日志</h2>

<h4 id="toc_11">找到需要优化的SQL的条件——对慢日志分析结果的第三部分进行剖析</h4>

<p>1、查询次数多且每次查询占用时间长的SQL<br/>
<code><br/>
通常pt_query_digest的前几个查询<br/>
</code></p>

<p>2、IO大的SQL<br/>
<code><br/>
注意pt_query_digest分析中的 Rows examine 项（扫描的行数是否过多）<br/>
</code><br/>
3、未命中的索引<br/>
<code><br/>
注意pt_query_digest分析中的 Rows examine 和Rows Send对比（扫描行数是否大大超过发送行数）<br/>
</code></p>

<h4 id="toc_12">对符合条件的SQL进行分析</h4>

<p>1、使用explain查询SQL的执行计划</p>

<pre><code>root@localhost:sakila 10:36:11 &gt;explain select customer_id,first_name,last_name from customer;
+----+-------------+----------+------------+------+---------------+------+---------+------+------+----------+-------+
| id | select_type | table    | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra |
+----+-------------+----------+------------+------+---------------+------+---------+------+------+----------+-------+
|  1 | SIMPLE      | customer | NULL       | ALL  | NULL          | NULL | NULL    | NULL |  599 |   100.00 | NULL  |
+----+-------------+----------+------------+------+---------------+------+---------+------+------+----------+-------+
1 row in set, 1 warning (0.00 sec)

注：
table：显示查询的哪一个表

**type**：显示使用了哪种连接类型，执行效率的排序从const（常驻查找，用于主键和唯一索引），eq_reg（常驻范围查找），ref（索引查找），range（索引的范围查找），index（索引的范围查找）和All（表扫描）

possible_keys:显示应用在这张表上可能的索引

key：实际使用的索引

key_len:索引的长度，**不损失精确性的前提下，越短越好。（索引页的存储率决定的）**

ref：显示索引的哪一列被使用了，有可能的话，返回一个常数。

rows：mysql认为必须检查用来返回数据的行数（表扫描的行数）。

extra：有两种一种是Using filesort一种是Using temporary，也就是文件排序（mysql需要额外的步骤来发现如何返回的行排序——根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行）和临时（执行时需要创建临时表来存储结果）表，如果出现这两种，就需要对sql语句进行优化了，临时表的出现一般出现在ORDER BY而不是GROUP BY。
</code></pre>

<h4 id="toc_13">对常见符合条件的SQL进行优化方式</h4>

<h5 id="toc_14">一、SQL语句的语法优化</h5>

<p>例：count（）经常被用于用来<strong>统计或计算</strong>表或数组的记录；如：在一条SQL中同时查出2006年和2007年电影的数量等</p>

<p><strong>第一步：优化的前提——语句执行的结果，语法和逻辑一定要对。</strong></p>

<p>首先区分count(*)、count(列名：如id)、count(1) 这三种的选择有时候执行结果是不一样的。<br/>
因为count(*) ,count(1)包括null值，count(id)忽略null值</p>

<pre><code>root@localhost:sakila 12:12:56 &gt;create table t(id int);

root@localhost:sakila 12:13:07 &gt;insert into t values(1),(2),(null);
Query OK, 3 rows affected (0.00 sec)
Records: 3  Duplicates: 0  Warnings: 0

root@localhost:sakila 12:13:55 &gt;select count(*),count(id),count(1) from t;
+----------+-----------+----------+
| count(*) | count(id) | count(1) |
+----------+-----------+----------+
|        3 |         2 |        3 |
+----------+-----------+----------+
1 row in set (0.00 sec)

</code></pre>

<p><strong>第二步：优化SQL逻辑及结果验证</strong></p>

<p>错误一、无法区分开2006和2007年电影数量</p>

<pre><code>root@localhost:sakila 12:54:45 &gt;select count(release_year=&#39;2006&#39; or release_year = &#39;2007&#39;) from film;
+-----------------------------------------------------+
| count(release_year=&#39;2006&#39; or release_year = &#39;2007&#39;) |
+-----------------------------------------------------+
|                                                1000 |
+-----------------------------------------------------+
1 row in set (0.00 sec)

root@localhost:sakila 12:54:58 &gt;explain select count(release_year=&#39;2006&#39; or release_year = &#39;2007&#39;) from film;  
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+
|  1 | SIMPLE      | film  | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 1000 |   100.00 | NULL  |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+
1 row in set, 1 warning (0.00 sec)

</code></pre>

<p>错误二、逻辑错误——release_year不可能同时为2006和2007</p>

<pre><code>root@localhost:sakila 12:55:08 &gt;select count(*) from where release_year = &#39;2006&#39; and release_year = &#39;2007&#39;;
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;where release_year = &#39;2006&#39; and release_year = &#39;2007&#39;&#39; at line 1
</code></pre>

<p>优化逻辑：利用count不统计null结果的特性，将不是查询年份的结果设置为null，并进行统计。</p>

<pre><code>root@localhost:sakila 12:20:31 &gt;select count(release_year=&#39;2006&#39; or null) as &#39;2006年电影数量&#39;,count(release_year=&#39;2007&#39; or null) as &#39;2007年   影数量&#39; from film;
+---------------------+---------------------+
| 2006年电影数量      | 2007年电影数量      |
+---------------------+---------------------+
|                1000 |                   0 |
+---------------------+---------------------+
1 row in set (0.01 sec)

</code></pre>

<h5 id="toc_15">二、SQL语句执行效率的优化</h5>

<p>例：max（）经常被用于<strong>查找特别大或最后的</strong>某一种事情的事务，如：查询最后的支付时间等</p>

<p><strong>第一步：分析SQL的计划任务</strong></p>

<pre><code>root@localhost:sakila 11:18:43 &gt;explain select max(payment_date) from payment;
+----+-------------+---------+------------+------+---------------+------+---------+------+-------+----------+-------+
| id | select_type | table   | partitions | type | possible_keys | key  | key_len | ref  | rows  | filtered | Extra |
+----+-------------+---------+------------+------+---------------+------+---------+------+-------+----------+-------+
|  1 | SIMPLE      | payment | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 16049 |   100.00 | NULL  |
+----+-------------+---------+------------+------+---------------+------+---------+------+-------+----------+-------+
1 row in set, 1 warning (0.00 sec)

分析结果：
进行了全表行数的扫描，无索引
</code></pre>

<p><strong>第二步：针对分析结果进行优化及验证</strong></p>

<pre><code>root@localhost:sakila 11:19:11 &gt;create index idx_paydate on payment(payment_date);
Query OK, 0 rows affected (0.11 sec)
Records: 0  Duplicates: 0  Warnings: 0

root@localhost:sakila 11:28:37 &gt;explain select max(payment_date) from payment;
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------------------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                        |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------------------+
|  1 | SIMPLE      | NULL  | NULL       | NULL | NULL          | NULL | NULL    | NULL | NULL |     NULL | Select tables optimized away |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------------------+
1 row in set, 1 warning (0.00 sec)

验证结果：
Extra有时候会显示“Select tables optimized away”，意思是没有更好的可优化的了
合理的解释是:
 1、 数据已经在内存中可以直接读取; 
 2、 数据可以被认为是一个经计算后的结果,如函数或表达式的值; 
 3、 一旦查询的结果被优化器&quot;预判&quot;可以不经执行就可以得到结果,所以才有&quot;not need to perform the select&quot;.
 
 分析：
 因为索引是按顺序排列的，通过索引的统计信息可以非常清楚的知道**最后一次统计信息**查询的数值结果（不管数据量有多大，执行频率有多高，结果是恒定的），因此并不需要一些表信息的操作，至此已最大的优化了此SQL的效率，尽可能大的减少了IO操作。——这种索引也称为覆盖索引
 
</code></pre>

<h5 id="toc_16">三、子查询的优化</h5>

<p>例：join子查询优化，为保证输出结果的逻辑正确性，因为需要注意有一个坑：是否有一对多的关系 （有重复数据）</p>

<pre><code>**分析表的结构**
root@localhost:sakila 01:21:14 &gt;show create table t;
+-------+-------------------------------------------------------------------------------------+
| Table | Create Table                                                                        |
+-------+-------------------------------------------------------------------------------------+
| t     | CREATE TABLE `t` (
  `id` int(11) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8 |
+-------+-------------------------------------------------------------------------------------+
1 row in set (0.00 sec)

分析：发现需要查询的数据列，为id，


**构建跨表查询的一对多的表结构：**
root@localhost:sakila 01:25:44 &gt;create table t1(tid int);
Query OK, 0 rows affected (0.04 sec)

root@localhost:sakila 01:31:18 &gt;insert into t1 values(1);
Query OK, 1 row affected (0.00 sec)

root@localhost:sakila 01:31:18 &gt;insert into t1 values(1);
Query OK, 1 row affected (0.00 sec)

root@localhost:sakila 01:43:36 &gt;select * from t where t.id in (select t1.tid from t1);
+------+
| id   |
+------+
|    1 |
+------+
1 row in set (0.00 sec)

root@localhost:sakila 01:43:48 &gt;select t.id from t join t1 on t.id = t1.tid;
+------+
| id   |
+------+
|    1 |
|    1 |
+------+
2 rows in set (0.01 sec)

分析：发现两条SQL查询结果不一致。


优化语句——使用distinct进行去重
root@localhost:sakila 01:48:14 &gt;select distinct t.id from t join t1 on t.id = t1.tid;
+------+
| id   |
+------+
|    1 |
+------+
1 row in set (0.00 sec)

</code></pre>

<h5 id="toc_17">四、分组的优化</h5>

<p>例：group by :如果我们需要对某些关联查询中的某一列进行group by，我们最好选择同一表中的列进行分组</p>

<pre><code>root@localhost:sakila 04:26:04 &gt;explain select actor.first_name,actor.last_name,count(*) from sakila.film_actor inner join sakila.actor using(actor_id) group by film_actor.actor_id;
+----+-------------+------------+------------+------+------------------------+---------+---------+-----------------------+------+----------+---------------------------------+
| id | select_type | table      | partitions | type | possible_keys          | key     | key_len | ref                   | rows | filtered | Extra                           |
+----+-------------+------------+------------+------+------------------------+---------+---------+-----------------------+------+----------+---------------------------------+
|  1 | SIMPLE      | actor      | NULL       | ALL  | PRIMARY                | NULL    | NULL    | NULL                  |  200 |   100.00 | Using temporary; Using filesort |
|  1 | SIMPLE      | film_actor | NULL       | ref  | PRIMARY,idx_fk_film_id | PRIMARY | 2       | sakila.actor.actor_id |   27 |   100.00 | Using index                     |
+----+-------------+------------+------------+------+------------------------+---------+---------+-----------------------+------+----------+---------------------------------+
2 rows in set, 1 warning (0.00 sec)

分析：
发现演员表使用了临时表和文件排序的方式

**增加一些过滤条件进行分组查询**
root@localhost:sakila 04:27:01 &gt;explain select actor.first_name,actor.last_name,c.cnt from sakila.actor inner join ( select actor_id, count(*) as cnt from sakila.film_actor group by actor_id ) as c using(actor_id);
+----+-------------+------------+------------+-------+------------------------+-------------+---------+-----------------------+------+----------+-------------+
| id | select_type | table      | partitions | type  | possible_keys          | key         | key_len | ref                   | rows | filtered | Extra       |
+----+-------------+------------+------------+-------+------------------------+-------------+---------+-----------------------+------+----------+-------------+
|  1 | PRIMARY     | actor      | NULL       | ALL   | PRIMARY                | NULL        | NULL    | NULL                  |  200 |   100.00 | NULL        |
|  1 | PRIMARY     | &lt;derived2&gt; | NULL       | ref   | &lt;auto_key0&gt;            | &lt;auto_key0&gt; | 2       | sakila.actor.actor_id |   27 |   100.00 | NULL        |
|  2 | DERIVED     | film_actor | NULL       | index | PRIMARY,idx_fk_film_id | PRIMARY     | 4       | NULL                  | 5462 |   100.00 | Using index |
+----+-------------+------------+------------+-------+------------------------+-------------+---------+-----------------------+------+----------+-------------+
3 rows in set, 1 warning (0.00 sec)

分析：
由于增加过滤条件，取消了临时表和文件排序。
增加过滤条件：尽量满足在子查询中添加过滤条件，而不是查询完后在外层增加过滤条件。


</code></pre>

<h5 id="toc_18">五、参数的优化</h5>

<p>例：limit 常用于分页处理，时常会伴随着order by 使用(文件过滤或文件排序等场景)，因而大多时侯会使用filesorts 这样会造成大量的io问题</p>

<pre><code>列出影片ID的说明——列表页的分类方式 
root@localhost:sakila 04:31:33 &gt;select film_id,description from sakila.film order by title limit 50,5;
+---------+---------------------------------------------------------------------------------------------------------------------------------+
| film_id | description                                                                                                                     |
+---------+---------------------------------------------------------------------------------------------------------------------------------+
|      51 | A Insightful Panorama of a Forensic Psychologist And a Mad Cow who must Build a Mad Scientist in The First Manned Space Station |
|      52 | A Thrilling Documentary of a Composer And a Monkey who must Find a Feminist in California                                       |
|      53 | A Epic Drama of a Madman And a Cat who must Face a A Shark in An Abandoned Amusement Park                                       |
|      54 | A Awe-Inspiring Drama of a Car And a Pastry Chef who must Chase a Crocodile in The First Manned Space Station                   |
|      55 | A Awe-Inspiring Story of a Feminist And a Cat who must Conquer a Dog in A Monastery                                             |
+---------+---------------------------------------------------------------------------------------------------------------------------------+
5 rows in set (0.00 sec)

root@localhost:sakila 04:45:06 &gt;explain select film_id,description from sakila.film order by title limit 50,5;
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra          |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+
|  1 | SIMPLE      | film  | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 1000 |   100.00 | Using filesort |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+
1 row in set, 1 warning (0.00 sec)

分析：
可以看出这个SQL使用了表扫描和文件排序的方式 ，这样如果表数据量很大会产生很大的IO问题

**优化步骤1、使用有索引的列或主键进行order by 操作**

root@localhost:sakila 04:57:53 &gt; select film_id, description from sakila.film order by film_id limit 50,5;       
+---------+---------------------------------------------------------------------------------------------------------------------------------+
| film_id | description                                                                                                                     |
+---------+---------------------------------------------------------------------------------------------------------------------------------+
|      51 | A Insightful Panorama of a Forensic Psychologist And a Mad Cow who must Build a Mad Scientist in The First Manned Space Station |
|      52 | A Thrilling Documentary of a Composer And a Monkey who must Find a Feminist in California                                       |
|      53 | A Epic Drama of a Madman And a Cat who must Face a A Shark in An Abandoned Amusement Park                                       |
|      54 | A Awe-Inspiring Drama of a Car And a Pastry Chef who must Chase a Crocodile in The First Manned Space Station                   |
|      55 | A Awe-Inspiring Story of a Feminist And a Cat who must Conquer a Dog in A Monastery                                             |
+---------+---------------------------------------------------------------------------------------------------------------------------------+
5 rows in set (0.00 sec)

root@localhost:sakila 04:48:55 &gt;explain select film_id, description from sakila.film order by film_id limit 50,5;
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------+
| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra |
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------+
|  1 | SIMPLE      | film  | NULL       | index | NULL          | PRIMARY | 2       | NULL |   55 |   100.00 | NULL  |
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------+
1 row in set, 1 warning (0.00 sec)

root@localhost:sakila 05:13:44 &gt;explain select film_id, description from sakila.film order by film_id limit 500,5;
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------+
| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra |
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------+
|  1 | SIMPLE      | film  | NULL       | index | NULL          | PRIMARY | 2       | NULL |  505 |   100.00 | NULL  |
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------+
1 row in set, 1 warning (0.00 sec)

分析：
因为innodb 引擎是使用主键的逻辑顺序进行排序的，经过优化发现已经不是全表扫描的方式了，但是如果参数的值增大，同样会造成扫描的行数远大于输出的结果

**优化步骤2、记录上次返回的主键，在下次查询时使用主键过滤。**
root@localhost:sakila 05:23:07 &gt;explain select film_id,description from sakila.film where film_id &gt; 500 and film_id &lt;=505 order by film_id limit 1,5;
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+
| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra       |
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+
|  1 | SIMPLE      | film  | NULL       | range | PRIMARY       | PRIMARY | 2       | NULL |    5 |   100.00 | Using where |
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+
1 row in set, 1 warning (0.00 sec)

分析：
避免了数据量大时扫描过多的记录，这样操作有一个条件：要求主键是按顺序增长和连续的，如果有主键空缺某列和多列结果将不准确。

解决办法是附加一个index_id的列为自增和索引



</code></pre>

<h3 id="toc_19">3. 对于本章9个节点的学习，做好总结的学习笔记。</h3>

<p>安红雷、刘宏伟、王恩志可以给予运维环境方面的支持。<br/>
作业：<br/>
查看视频，针对以上9个学习点，形成笔记，转换PDF上传至Seafile。<br/>
注意事项：<br/>
完成学习后，修改计划完成日期为真实完成日期。</p>

                    
                </div>
                <p class="post-meta">
                    <time class="post-time" datetime="2018-01-13T18:40:34+08:00"itemprop="datePublished">Created by Tisoga at 2018/1/13</time>
                </p>
            </header>
            <div class="post-content" itemprop="articleBody">
                <p>慕课网视频地址：<a href="https://www.imooc.com/learn/194">https://www.imooc.com/learn/194</a><br/>
课程要点：</p>

<h2 id="toc_0">1. 演示数据库我会调配资源提供给大家使用；</h2>

<h3 id="toc_1">下载sakila数据库</h3>

<pre><code>http://dev.mysql.com/doc/index-other.html
tar xf sakila-db.tar
source /data/backup/sakila-db/sakila-schema.sql
source /data/backup/sakila-db/sakila-data.sql;

进入示例：
root@localhost:(none) 06:39:23 &gt;use sakila;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
root@localhost:sakila 06:39:33 &gt;show tables;
+----------------------------+
| Tables_in_sakila           |
+----------------------------+
| actor                      |
| actor_info                 |
| address                    |
| category                   |
| city                       |
| country                    |
| customer                   |
| customer_list              |
| film                       |
| film_actor                 |
| film_category              |
| film_list                  |
| film_text                  |
| inventory                  |
| language                   |
| nicer_but_slower_film_list |
| payment                    |
| rental                     |
| sales_by_film_category     |
| sales_by_store             |
| staff                      |
| staff_list                 |
| store                      |
+----------------------------+
23 rows in set (0.00 sec)
</code></pre>

<h3 id="toc_2">2. SQL语句的优化</h3>

<h4 id="toc_3">第一步：哪些SQL及索引是需要优化的——如何发现有问题的SQL</h4>

<p>主要使用Mysql慢日志对效率有问题的SQL进行监控</p>

<h4 id="toc_4">开启及设置慢查询日志——针对mysql实例非数据库</h4>

<pre><code>root@localhost:sakila 06:56:56 &gt;show variables like &#39;slow_query_log&#39;;
+----------------+-------+
| Variable_name  | Value |
+----------------+-------+
| slow_query_log | ON    |
+----------------+-------+
1 row in set (0.00 sec)

root@localhost:sakila 06:58:05 &gt;show variables like &#39;slow_query_log_file&#39;;
+---------------------+--------------------------------+
| Variable_name       | Value                          |
+---------------------+--------------------------------+
| slow_query_log_file | /data/mysql/3306/logs/slow.log |
+---------------------+--------------------------------+
1 row in set (0.00 sec)

**开启记录没有使用索引的SQL**
root@localhost:sakila 06:58:41 &gt;set global log_queries_not_using_indexes=on;
Query OK, 0 rows affected (0.00 sec)

**慢查询日志设置的记录超时时间**
root@localhost:sakila 07:01:53 &gt;set global long_query_time=1;
Query OK, 0 rows affected (0.00 sec)
</code></pre>

<h4 id="toc_5">查询语句的慢查询结构信息</h4>

<pre><code>root@localhost:sakila 07:02:17 &gt;select * from store limit 10;
+----------+------------------+------------+---------------------+
| store_id | manager_staff_id | address_id | last_update         |
+----------+------------------+------------+---------------------+
|        1 |                1 |          1 | 2006-02-15 04:57:12 |
|        2 |                2 |          2 | 2006-02-15 04:57:12 |
+----------+------------------+------------+---------------------+
2 rows in set (0.00 sec)

root@localhost:sakila 07:18:09 &gt;show variables like &#39;slow%&#39;;
+---------------------+--------------------------------+
| Variable_name       | Value                          |
+---------------------+--------------------------------+
| slow_launch_time    | 2                              |
| slow_query_log      | ON                             |
| slow_query_log_file | /data/mysql/3306/logs/slow.log |
+---------------------+--------------------------------+
3 rows in set (0.00 sec)
</code></pre>

<pre><code>root@anhonglei-test-bjqw:~ # tail -fn10 /data/mysql/3306/logs/slow.log
# User@Host: root[root] @ localhost []  Id:     4
# Query_time: 3.012571  Lock_time: 0.000523 Rows_sent: 0  Rows_examined: 0
SET timestamp=1513930484;
GRANT ALL PRIVILEGES ON *.* TO &#39;admin&#39;@&#39;localhost&#39; IDENTIFIED WITH &#39;mysql_native_password&#39; AS &#39;*CC5F1D1D66012B7EE904E3C06451B244778D4C31&#39;;

执行时间
# Time: 2018-01-13T19:18:09.233197+08:00

执行主机的信息
# User@Host: root[root] @ localhost []  Id:    21

SQL语句执行的信息：查询执行时间，锁定时间，发送的行数，扫描的行数
# Query_time: 0.000597  Lock_time: 0.000207 Rows_sent: 2  Rows_examined: 2
use sakila;

SQL执行的时间：时间戳形式
SET timestamp=1515842289;

执行的SQL内容
select * from store limit 10;


</code></pre>

<h4 id="toc_6">分析慢查询日志：使用工具批量分析慢查询日志得出结果</h4>

<h5 id="toc_7">Mysql自带工具：mysqldumpslow</h5>

<pre><code>root@anhonglei-test-bjqw:~ # mysqldumpslow --help
Usage: mysqldumpslow [ OPTS... ] [ LOGS... ]

Parse and summarize the MySQL slow query log. Options are

  --verbose    verbose
  --debug      debug
  --help       write this text to standard output

  -v           verbose
  -d           debug
  -s ORDER     what to sort by (al, at, ar, c, l, r, t), &#39;at&#39; is default
                al: average lock time
                ar: average rows sent
                at: average query time
                 c: count
                 l: lock time
                 r: rows sent
                 t: query time  
  -r           reverse the sort order (largest last instead of first)
  -t NUM       just show the top n queries
  -a           don&#39;t abstract all numbers to N and strings to &#39;S&#39;
  -n NUM       abstract numbers with at least n digits within names
  -g PATTERN   grep: only consider stmts that include this string
  -h HOSTNAME  hostname of db server for *-slow.log filename (can be wildcard),
               default is &#39;*&#39;, i.e. match all
  -i NAME      name of server instance (if using mysql.server startup script)
  -l           don&#39;t subtract lock time from total time
</code></pre>

<pre><code>root@anhonglei-test-bjqw:~ # mysqldumpslow -t 1 /data/mysql/3306/logs/slow.log

Reading mysql slow query log from /data/mysql/3306/logs/slow.log

执行次数，执行时间，锁时间，发送的行数，执行主机信息，
Count: 1  Time=3.01s (3s)  Lock=0.00s (0s)  Rows=0.0 (0), root[root]@localhost

  执行的语句
  GRANT ALL PRIVILEGES ON *.* TO &#39;S&#39;@&#39;S&#39; IDENTIFIED WITH &#39;S&#39; AS &#39;S&#39;
</code></pre>

<h5 id="toc_8">常用分析工具：pt-query-digest</h5>

<p>pt-query-digest是用于分析mysql慢查询的一个工具，它也可以分析binlog、General log、slowlog，也可以通过SHOWPROCESSLIST或者通过tcpdump抓取的MySQL协议数据来进行分析。可以把分析结果输出到文件中，分析过程是先对查询语句的条件进行参数化，然后对参数化以后的查询进行分组统计，统计出各查询的执行时间、次数、占比等，可以借助分析结果找出问题进行优化。</p>

<p>1:安装于Perl相关的模块<br/>
 yum -y install perl perl-IO-Socket-SSL perl-DBD-MySQL perl-Time-HiRes<br/><br/>
 2:下载和安装percona toolkit的包<br/>
wget <a href="https://www.percona.com/downloads/percona-toolkit/2.2.16/RPM/percona-toolkit-2.2.16-1.noarch.rpm">https://www.percona.com/downloads/percona-toolkit/2.2.16/RPM/percona-toolkit-2.2.16-1.noarch.rpm</a> &amp;&amp; yum localinstall -y  percona-toolkit-2.2.16-1.noarch.rpm</p>

<pre><code>root@anhonglei-test-bjqw:~ # pt-query-digest --help
pt-query-digest analyzes MySQL queries from slow, general, and binary log files.
It can also analyze queries from C&lt;SHOW PROCESSLIST&gt; and MySQL protocol data
from tcpdump.  By default, queries are grouped by fingerprint and reported in
descending order of query time (i.e. the slowest queries first).  If no C&lt;FILES&gt;
are given, the tool reads C&lt;STDIN&gt;.  The optional C&lt;DSN&gt; is used for certain
options like L&lt;&quot;--since&quot;&gt; and L&lt;&quot;--until&quot;&gt;.  For more details, please use the
--help option, or try &#39;perldoc /bin/pt-query-digest&#39; for complete documentation.

Usage: pt-query-digest [OPTIONS] [FILES] [DSN]

Options:

  --ask-pass                  Prompt for a password when connecting to MySQL
  --attribute-aliases=a       List of attribute|alias,etc (default db|Schema)
  --attribute-value-limit=i   A sanity limit for attribute values (default
                              4294967296)
  --charset=s             -A  Default character set
  --config=A                  Read this comma-separated list of config files;
                              if specified, this must be the first option on
                              the command line
  --[no]continue-on-error     Continue parsing even if there is an error (
                              default yes)
  --[no]create-history-table  Create the --history table if it does not exist (
                              default yes)
  --[no]create-review-table   Create the --review table if it does not exist (
                              default yes)
  --daemonize                 Fork to the background and detach from the shell
  --database=s            -D  Connect to this database
  --defaults-file=s       -F  Only read mysql options from the given file
  --embedded-attributes=a     Two Perl regex patterns to capture pseudo-
                              attributes embedded in queries
  --expected-range=a          Explain items when there are more or fewer than
                              expected (default 5,10)
  --explain=d                 Run EXPLAIN for the sample query with this DSN
                              and print results
  --filter=s                  Discard events for which this Perl code doesn&#39;t
                              return true
  --group-by=A                Which attribute of the events to group by (
                              default fingerprint)
  --help                      Show help and exit
  --history=d                 Save metrics for each query class in the given
                              table. pt-query-digest saves query metrics (query
                              time, lock time, etc.) to this table so you can
                              see how query classes change over time
  --host=s                -h  Connect to host
  --ignore-attributes=a       Do not aggregate these attributes (default arg,
                              cmd, insert_id, ip, port, Thread_id, timestamp,
                              exptime, flags, key, res, val, server_id, offset,
                              end_log_pos, Xid)
  --inherit-attributes=a      If missing, inherit these attributes from the
                              last event that had them (default db,ts)
  --interval=f                How frequently to poll the processlist, in
                              seconds (default .1)
  --iterations=i              How many times to iterate through the collect-and-
                              report cycle (default 1)
  --limit=A                   Limit output to the given percentage or count (
                              default 95%:20)
  --log=s                     Print all output to this file when daemonized
  --order-by=A                Sort events by this attribute and aggregate
                              function (default Query_time:sum)
  --outliers=a                Report outliers by attribute:percentile:count (
                              default Query_time:1:10)
  --output=s                  How to format and print the query analysis
                              results (default report)
  --password=s            -p  Password to use when connecting
  --pid=s                     Create the given PID file
  --port=i                -P  Port number to use for connection
  --processlist=d             Poll this DSN&#39;s processlist for queries, with --
                              interval sleep between
  --progress=a                Print progress reports to STDERR (default time,30)
  --read-timeout=m            Wait this long for an event from the input; 0 to
                              wait forever (default 0).  Optional suffix s=
                              seconds, m=minutes, h=hours, d=days; if no
                              suffix, s is used.
  --[no]report                Print query analysis reports for each --group-by
                              attribute (default yes)
  --report-all                Report all queries, even ones that have been
                              reviewed
  --report-format=A           Print these sections of the query analysis
                              report (default rusage,date,hostname,files,header,
                              profile,query_report,prepared)
  --report-histogram=s        Chart the distribution of this attribute&#39;s
                              values (default Query_time)
  --resume=s                  If specified, the tool writes the last file
                              offset, if there is one, to the given filename
  --review=d                  Save query classes for later review, and don&#39;t
                              report already reviewed classes
  --run-time=m                How long to run for each --iterations.  Optional
                              suffix s=seconds, m=minutes, h=hours, d=days; if
                              no suffix, s is used.
  --run-time-mode=s           Set what the value of --run-time operates on (
                              default clock)
  --sample=i                  Filter out all but the first N occurrences of
                              each query
  --set-vars=A                Set the MySQL variables in this comma-separated
                              list of variable=value pairs
  --show-all=H                Show all values for these attributes
  --since=s                   Parse only queries newer than this value (parse
                              queries since this date)
  --socket=s              -S  Socket file to use for connection
  --timeline                  Show a timeline of events
  --type=A                    The type of input to parse (default slowlog)
  --until=s                   Parse only queries older than this value (parse
                              queries until this date)
  --user=s                -u  User for login if not current user
  --variations=A              Report the number of variations in these
                              attributes&#39; values
  --version                   Show version and exit
  --[no]version-check         Check for the latest version of Percona Toolkit,
                              MySQL, and other programs (default yes)
  --watch-server=s            This option tells pt-query-digest which server IP
                              address and port (like &quot;10.0.0.1:3306&quot;) to watch
                              when parsing tcpdump (for --type tcpdump); all
                              other servers are ignored

Option types: s=string, i=integer, f=float, h/H/a/A=comma-separated list, d=DSN, z=size, m=time

Rules:

  This tool accepts additional command-line arguments. Refer to the SYNOPSIS and usage information for details.

DSN syntax is key=value[,key=value...]  Allowable DSN keys:

  KEY  COPY  MEANING
  ===  ====  =============================================
  A    yes   Default character set
  D    yes   Default database to use when connecting to MySQL
  F    yes   Only read default options from the given file
  P    yes   Port number to use for connection
  S    yes   Socket file to use for connection
  h    yes   Connect to host
  p    yes   Password to use when connecting
  t    no    The --review or --history table
  u    yes   User for login if not current user

  If the DSN is a bareword, the word is treated as the &#39;h&#39; key.

Options and values after processing arguments:

  --ask-pass                  FALSE
  --attribute-aliases         db|Schema
  --attribute-value-limit     4294967296
  --charset                   (No value)
  --config                    /etc/percona-toolkit/percona-toolkit.conf,/etc/percona-toolkit/pt-query-digest.conf,/root/.percona-toolkit.conf,/root/.pt-query-digest.conf
  --continue-on-error         TRUE
  --create-history-table      TRUE
  --create-review-table       TRUE
  --daemonize                 FALSE
  --database                  (No value)
  --defaults-file             (No value)
  --embedded-attributes       (No value)
  --expected-range            5,10
  --explain                   (No value)
  --filter                    (No value)
  --group-by                  fingerprint
  --help                      TRUE
  --history                   (No value)
  --host                      (No value)
  --ignore-attributes         arg,cmd,insert_id,ip,port,Thread_id,timestamp,exptime,flags,key,res,val,server_id,offset,end_log_pos,Xid
  --inherit-attributes        db,ts
  --interval                  .1
  --iterations                1
  --limit                     95%:20
  --log                       (No value)
  --order-by                  Query_time:sum
  --outliers                  Query_time:1:10
  --output                    report
  --password                  (No value)
  --pid                       (No value)
  --port                      (No value)
  --processlist               (No value)
  --progress                  time,30
  --read-timeout              0
  --report                    TRUE
  --report-all                FALSE
  --report-format             rusage,date,hostname,files,header,profile,query_report,prepared
  --report-histogram          Query_time
  --resume                    (No value)
  --review                    (No value)
  --run-time                  (No value)
  --run-time-mode             clock
  --sample                    (No value)
  --set-vars                  
  --show-all                  
  --since                     (No value)
  --socket                    (No value)
  --timeline                  FALSE
  --type                      slowlog
  --until                     (No value)
  --user                      (No value)
  --variations                
  --version                   FALSE
  --version-check             TRUE
  --watch-server              (No value)
</code></pre>

<pre><code>root@anhonglei-test-bjqw:~ # pt-query-digest /data/mysql/3306/logs/slow.log &gt; slow_log.report
*******************************************************************
 Using the default of SSL_verify_mode of SSL_VERIFY_NONE for client
 is deprecated! Please set SSL_verify_mode to SSL_VERIFY_PEER
 together with SSL_ca_file|SSL_ca_path for verification.
 If you really don&#39;t want to verify the certificate and keep the
 connection open to Man-In-The-Middle attacks please set
 SSL_verify_mode explicitly to SSL_VERIFY_NONE in your application.
*******************************************************************
  at /bin/pt-query-digest line 11847.
*******************************************************************
 Using the default of SSL_verify_mode of SSL_VERIFY_NONE for client
 is deprecated! Please set SSL_verify_mode to SSL_VERIFY_PEER
 together with SSL_ca_file|SSL_ca_path for verification.
 If you really don&#39;t want to verify the certificate and keep the
 connection open to Man-In-The-Middle attacks please set
 SSL_verify_mode explicitly to SSL_VERIFY_NONE in your application.
*******************************************************************
  at /bin/pt-query-digest line 11847.
  
  ##分析结果信息：
  root@anhonglei-test-bjqw:~ # cat slow_log.report 

# A software update is available:
#   * The current version for Percona::Toolkit is 3.0.5

##头部信息：
#默认95%的SQL总耗时：用户时间，系统时间 ，。。。
# 310ms user time, 40ms system time, 27.80M rss, 236.60M vsz
# Current date: Sat Jan 13 21:58:05 2018
# Hostname: anhonglei-test-bjqw.bd-yg.com
# Files: /data/mysql/3306/logs/slow.log

#包含的SQL总数，不同的SQL个数，
# Overall: 2 total, 2 unique, 0 QPS, 0x concurrency ______________________

#各结果耗时      总计    最小    最大  平均      包含数量
# Attribute          total     min     max     avg     95%  stddev  median
# ============     ======= ======= ======= ======= ======= ======= =======
# Exec time             3s   597us      3s      2s      3s      2s      2s
# Lock time          730us   207us   523us   365us   523us   223us   365us
# Rows sent              2       0       2       1       2    1.41       1
# Rows examine           2       0       2       1       2    1.41       1
# Query size           165      28     137   82.50     137   77.07   82.50
## 对比Rows sent 和Rows examine 数据差距是否很大，判断索引是否有效。


##相关表的执行信息：
# Profile
# Rank Query ID           Response time Calls R/Call V/M   Item
# ==== ================== ============= ===== ====== ===== =========

#   表名 ，    响应时间   单SQL占比    执行次数   读取行数    相关具体操作
#    1 0x80591928D0217D4E 3.0126 100.0%     1 3.0126  0.00 
# MISC 0xMISC              0.0006  0.0%     1 0.0006   0.0 &lt;1 ITEMS&gt;


##单条SQL的具体信息：
# Query 1: 0 QPS, 0x concurrency, ID 0x80591928D0217D4E at byte 0 ________
# This item is included in the report because it matches --limit.
# Scores: V/M = 0.00

#具体信息   总时间百分比  总数 最小  最大  。。。
# Attribute    pct   total     min     max     avg     95%  stddev  median
# ============ === ======= ======= ======= ======= ======= ======= =======
# Count         50       1
# Exec time     99      3s      3s      3s      3s      3s       0      3s
# Lock time     71   523us   523us   523us   523us   523us       0   523us
# Rows sent      0       0       0       0       0       0       0       0
# Rows examine   0       0       0       0       0       0       0       0
# Query size    83     137     137     137     137     137       0     137
# String:
# Hosts        localhost
# Time         2017-12-22T16:14:44.780690+08:00
# Users        root
# Query_time distribution
#   1us
#  10us
# 100us
#   1ms
#  10ms
# 100ms
#    1s  ################################################################
#  10s+

#具体的语句内容
GRANT ALL PRIVILEGES ON *.* TO &#39;admin&#39;@&#39;localhost&#39; IDENTIFIED WITH &#39;mysql_native_password&#39; AS &#39;*CC5F1D1D66012B7EE904E3C06451B244778D4C31&#39;\G
  
</code></pre>

<h5 id="toc_9">用法示例</h5>

<pre><code>(1)直接分析慢查询文件:
pt-query-digest  slow.log &gt; slow_report.log

(2)分析最近12小时内的查询：

pt-query-digest  --since=12h  slow.log &gt; slow_report2.log

(3)分析指定时间范围内的查询：

pt-query-digest slow.log --since &#39;2014-04-17 09:30:00&#39; --until &#39;2014-04-17 10:00:00&#39;&gt; &gt; slow_report3.log

(4)分析指含有select语句的慢查询
pt-query-digest--filter &#39;$event-&gt;{fingerprint} =~ m/^select/i&#39; slow.log&gt; slow_report4.log

(5) 针对某个用户的慢查询
pt-query-digest--filter &#39;($event-&gt;{user} || &quot;&quot;) =~ m/^root/i&#39; slow.log&gt; slow_report5.log

(6) 查询所有所有的全表扫描或full join的慢查询
pt-query-digest--filter &#39;(($event-&gt;{Full_scan} || &quot;&quot;) eq &quot;yes&quot;) ||(($event-&gt;{Full_join} || &quot;&quot;) eq &quot;yes&quot;)&#39; slow.log&gt; slow_report6.log

(7)把查询保存到query_review表
pt-query-digest  --user=root –password=abc123 --review  h=localhost,D=test,t=query_review--create-review-table  slow.log

(8)把查询保存到query_history表
pt-query-digest  --user=root –password=abc123 --review  h=localhost,D=test,t=query_ history--create-review-table  slow.log_20140401
pt-query-digest  --user=root –password=abc123--review  h=localhost,D=test,t=query_history--create-review-table  slow.log_20140402

(9)通过tcpdump抓取mysql的tcp协议数据，然后再分析
tcpdump -s 65535 -x -nn -q -tttt -i any -c 1000 port 3306 &gt; mysql.tcp.txt
pt-query-digest --type tcpdump mysql.tcp.txt&gt; slow_report9.log

(10)分析binlog
mysqlbinlog mysql-bin.000093 &gt; mysql-bin000093.sql
pt-query-digest  --type=binlog  mysql-bin000093.sql &gt; slow_report10.log

(11)分析general log
pt-query-digest  --type=genlog  localhost.log &gt; slow_report11.log


官方文档：http://www.percona.com/doc/percona-toolkit/2.2/pt-query-digest.html
</code></pre>

<h2 id="toc_10">第二步 分析慢查询日志</h2>

<h4 id="toc_11">找到需要优化的SQL的条件——对慢日志分析结果的第三部分进行剖析</h4>

<p>1、查询次数多且每次查询占用时间长的SQL<br/>
<code><br/>
通常pt_query_digest的前几个查询<br/>
</code></p>

<p>2、IO大的SQL<br/>
<code><br/>
注意pt_query_digest分析中的 Rows examine 项（扫描的行数是否过多）<br/>
</code><br/>
3、未命中的索引<br/>
<code><br/>
注意pt_query_digest分析中的 Rows examine 和Rows Send对比（扫描行数是否大大超过发送行数）<br/>
</code></p>

<h4 id="toc_12">对符合条件的SQL进行分析</h4>

<p>1、使用explain查询SQL的执行计划</p>

<pre><code>root@localhost:sakila 10:36:11 &gt;explain select customer_id,first_name,last_name from customer;
+----+-------------+----------+------------+------+---------------+------+---------+------+------+----------+-------+
| id | select_type | table    | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra |
+----+-------------+----------+------------+------+---------------+------+---------+------+------+----------+-------+
|  1 | SIMPLE      | customer | NULL       | ALL  | NULL          | NULL | NULL    | NULL |  599 |   100.00 | NULL  |
+----+-------------+----------+------------+------+---------------+------+---------+------+------+----------+-------+
1 row in set, 1 warning (0.00 sec)

注：
table：显示查询的哪一个表

**type**：显示使用了哪种连接类型，执行效率的排序从const（常驻查找，用于主键和唯一索引），eq_reg（常驻范围查找），ref（索引查找），range（索引的范围查找），index（索引的范围查找）和All（表扫描）

possible_keys:显示应用在这张表上可能的索引

key：实际使用的索引

key_len:索引的长度，**不损失精确性的前提下，越短越好。（索引页的存储率决定的）**

ref：显示索引的哪一列被使用了，有可能的话，返回一个常数。

rows：mysql认为必须检查用来返回数据的行数（表扫描的行数）。

extra：有两种一种是Using filesort一种是Using temporary，也就是文件排序（mysql需要额外的步骤来发现如何返回的行排序——根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行）和临时（执行时需要创建临时表来存储结果）表，如果出现这两种，就需要对sql语句进行优化了，临时表的出现一般出现在ORDER BY而不是GROUP BY。
</code></pre>

<h4 id="toc_13">对常见符合条件的SQL进行优化方式</h4>

<h5 id="toc_14">一、SQL语句的语法优化</h5>

<p>例：count（）经常被用于用来<strong>统计或计算</strong>表或数组的记录；如：在一条SQL中同时查出2006年和2007年电影的数量等</p>

<p><strong>第一步：优化的前提——语句执行的结果，语法和逻辑一定要对。</strong></p>

<p>首先区分count(*)、count(列名：如id)、count(1) 这三种的选择有时候执行结果是不一样的。<br/>
因为count(*) ,count(1)包括null值，count(id)忽略null值</p>

<pre><code>root@localhost:sakila 12:12:56 &gt;create table t(id int);

root@localhost:sakila 12:13:07 &gt;insert into t values(1),(2),(null);
Query OK, 3 rows affected (0.00 sec)
Records: 3  Duplicates: 0  Warnings: 0

root@localhost:sakila 12:13:55 &gt;select count(*),count(id),count(1) from t;
+----------+-----------+----------+
| count(*) | count(id) | count(1) |
+----------+-----------+----------+
|        3 |         2 |        3 |
+----------+-----------+----------+
1 row in set (0.00 sec)

</code></pre>

<p><strong>第二步：优化SQL逻辑及结果验证</strong></p>

<p>错误一、无法区分开2006和2007年电影数量</p>

<pre><code>root@localhost:sakila 12:54:45 &gt;select count(release_year=&#39;2006&#39; or release_year = &#39;2007&#39;) from film;
+-----------------------------------------------------+
| count(release_year=&#39;2006&#39; or release_year = &#39;2007&#39;) |
+-----------------------------------------------------+
|                                                1000 |
+-----------------------------------------------------+
1 row in set (0.00 sec)

root@localhost:sakila 12:54:58 &gt;explain select count(release_year=&#39;2006&#39; or release_year = &#39;2007&#39;) from film;  
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+
|  1 | SIMPLE      | film  | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 1000 |   100.00 | NULL  |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+
1 row in set, 1 warning (0.00 sec)

</code></pre>

<p>错误二、逻辑错误——release_year不可能同时为2006和2007</p>

<pre><code>root@localhost:sakila 12:55:08 &gt;select count(*) from where release_year = &#39;2006&#39; and release_year = &#39;2007&#39;;
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;where release_year = &#39;2006&#39; and release_year = &#39;2007&#39;&#39; at line 1
</code></pre>

<p>优化逻辑：利用count不统计null结果的特性，将不是查询年份的结果设置为null，并进行统计。</p>

<pre><code>root@localhost:sakila 12:20:31 &gt;select count(release_year=&#39;2006&#39; or null) as &#39;2006年电影数量&#39;,count(release_year=&#39;2007&#39; or null) as &#39;2007年   影数量&#39; from film;
+---------------------+---------------------+
| 2006年电影数量      | 2007年电影数量      |
+---------------------+---------------------+
|                1000 |                   0 |
+---------------------+---------------------+
1 row in set (0.01 sec)

</code></pre>

<h5 id="toc_15">二、SQL语句执行效率的优化</h5>

<p>例：max（）经常被用于<strong>查找特别大或最后的</strong>某一种事情的事务，如：查询最后的支付时间等</p>

<p><strong>第一步：分析SQL的计划任务</strong></p>

<pre><code>root@localhost:sakila 11:18:43 &gt;explain select max(payment_date) from payment;
+----+-------------+---------+------------+------+---------------+------+---------+------+-------+----------+-------+
| id | select_type | table   | partitions | type | possible_keys | key  | key_len | ref  | rows  | filtered | Extra |
+----+-------------+---------+------------+------+---------------+------+---------+------+-------+----------+-------+
|  1 | SIMPLE      | payment | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 16049 |   100.00 | NULL  |
+----+-------------+---------+------------+------+---------------+------+---------+------+-------+----------+-------+
1 row in set, 1 warning (0.00 sec)

分析结果：
进行了全表行数的扫描，无索引
</code></pre>

<p><strong>第二步：针对分析结果进行优化及验证</strong></p>

<pre><code>root@localhost:sakila 11:19:11 &gt;create index idx_paydate on payment(payment_date);
Query OK, 0 rows affected (0.11 sec)
Records: 0  Duplicates: 0  Warnings: 0

root@localhost:sakila 11:28:37 &gt;explain select max(payment_date) from payment;
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------------------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                        |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------------------+
|  1 | SIMPLE      | NULL  | NULL       | NULL | NULL          | NULL | NULL    | NULL | NULL |     NULL | Select tables optimized away |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------------------+
1 row in set, 1 warning (0.00 sec)

验证结果：
Extra有时候会显示“Select tables optimized away”，意思是没有更好的可优化的了
合理的解释是:
 1、 数据已经在内存中可以直接读取; 
 2、 数据可以被认为是一个经计算后的结果,如函数或表达式的值; 
 3、 一旦查询的结果被优化器&quot;预判&quot;可以不经执行就可以得到结果,所以才有&quot;not need to perform the select&quot;.
 
 分析：
 因为索引是按顺序排列的，通过索引的统计信息可以非常清楚的知道**最后一次统计信息**查询的数值结果（不管数据量有多大，执行频率有多高，结果是恒定的），因此并不需要一些表信息的操作，至此已最大的优化了此SQL的效率，尽可能大的减少了IO操作。——这种索引也称为覆盖索引
 
</code></pre>

<h5 id="toc_16">三、子查询的优化</h5>

<p>例：join子查询优化，为保证输出结果的逻辑正确性，因为需要注意有一个坑：是否有一对多的关系 （有重复数据）</p>

<pre><code>**分析表的结构**
root@localhost:sakila 01:21:14 &gt;show create table t;
+-------+-------------------------------------------------------------------------------------+
| Table | Create Table                                                                        |
+-------+-------------------------------------------------------------------------------------+
| t     | CREATE TABLE `t` (
  `id` int(11) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8 |
+-------+-------------------------------------------------------------------------------------+
1 row in set (0.00 sec)

分析：发现需要查询的数据列，为id，


**构建跨表查询的一对多的表结构：**
root@localhost:sakila 01:25:44 &gt;create table t1(tid int);
Query OK, 0 rows affected (0.04 sec)

root@localhost:sakila 01:31:18 &gt;insert into t1 values(1);
Query OK, 1 row affected (0.00 sec)

root@localhost:sakila 01:31:18 &gt;insert into t1 values(1);
Query OK, 1 row affected (0.00 sec)

root@localhost:sakila 01:43:36 &gt;select * from t where t.id in (select t1.tid from t1);
+------+
| id   |
+------+
|    1 |
+------+
1 row in set (0.00 sec)

root@localhost:sakila 01:43:48 &gt;select t.id from t join t1 on t.id = t1.tid;
+------+
| id   |
+------+
|    1 |
|    1 |
+------+
2 rows in set (0.01 sec)

分析：发现两条SQL查询结果不一致。


优化语句——使用distinct进行去重
root@localhost:sakila 01:48:14 &gt;select distinct t.id from t join t1 on t.id = t1.tid;
+------+
| id   |
+------+
|    1 |
+------+
1 row in set (0.00 sec)

</code></pre>

<h5 id="toc_17">四、分组的优化</h5>

<p>例：group by :如果我们需要对某些关联查询中的某一列进行group by，我们最好选择同一表中的列进行分组</p>

<pre><code>root@localhost:sakila 04:26:04 &gt;explain select actor.first_name,actor.last_name,count(*) from sakila.film_actor inner join sakila.actor using(actor_id) group by film_actor.actor_id;
+----+-------------+------------+------------+------+------------------------+---------+---------+-----------------------+------+----------+---------------------------------+
| id | select_type | table      | partitions | type | possible_keys          | key     | key_len | ref                   | rows | filtered | Extra                           |
+----+-------------+------------+------------+------+------------------------+---------+---------+-----------------------+------+----------+---------------------------------+
|  1 | SIMPLE      | actor      | NULL       | ALL  | PRIMARY                | NULL    | NULL    | NULL                  |  200 |   100.00 | Using temporary; Using filesort |
|  1 | SIMPLE      | film_actor | NULL       | ref  | PRIMARY,idx_fk_film_id | PRIMARY | 2       | sakila.actor.actor_id |   27 |   100.00 | Using index                     |
+----+-------------+------------+------------+------+------------------------+---------+---------+-----------------------+------+----------+---------------------------------+
2 rows in set, 1 warning (0.00 sec)

分析：
发现演员表使用了临时表和文件排序的方式

**增加一些过滤条件进行分组查询**
root@localhost:sakila 04:27:01 &gt;explain select actor.first_name,actor.last_name,c.cnt from sakila.actor inner join ( select actor_id, count(*) as cnt from sakila.film_actor group by actor_id ) as c using(actor_id);
+----+-------------+------------+------------+-------+------------------------+-------------+---------+-----------------------+------+----------+-------------+
| id | select_type | table      | partitions | type  | possible_keys          | key         | key_len | ref                   | rows | filtered | Extra       |
+----+-------------+------------+------------+-------+------------------------+-------------+---------+-----------------------+------+----------+-------------+
|  1 | PRIMARY     | actor      | NULL       | ALL   | PRIMARY                | NULL        | NULL    | NULL                  |  200 |   100.00 | NULL        |
|  1 | PRIMARY     | &lt;derived2&gt; | NULL       | ref   | &lt;auto_key0&gt;            | &lt;auto_key0&gt; | 2       | sakila.actor.actor_id |   27 |   100.00 | NULL        |
|  2 | DERIVED     | film_actor | NULL       | index | PRIMARY,idx_fk_film_id | PRIMARY     | 4       | NULL                  | 5462 |   100.00 | Using index |
+----+-------------+------------+------------+-------+------------------------+-------------+---------+-----------------------+------+----------+-------------+
3 rows in set, 1 warning (0.00 sec)

分析：
由于增加过滤条件，取消了临时表和文件排序。
增加过滤条件：尽量满足在子查询中添加过滤条件，而不是查询完后在外层增加过滤条件。


</code></pre>

<h5 id="toc_18">五、参数的优化</h5>

<p>例：limit 常用于分页处理，时常会伴随着order by 使用(文件过滤或文件排序等场景)，因而大多时侯会使用filesorts 这样会造成大量的io问题</p>

<pre><code>列出影片ID的说明——列表页的分类方式 
root@localhost:sakila 04:31:33 &gt;select film_id,description from sakila.film order by title limit 50,5;
+---------+---------------------------------------------------------------------------------------------------------------------------------+
| film_id | description                                                                                                                     |
+---------+---------------------------------------------------------------------------------------------------------------------------------+
|      51 | A Insightful Panorama of a Forensic Psychologist And a Mad Cow who must Build a Mad Scientist in The First Manned Space Station |
|      52 | A Thrilling Documentary of a Composer And a Monkey who must Find a Feminist in California                                       |
|      53 | A Epic Drama of a Madman And a Cat who must Face a A Shark in An Abandoned Amusement Park                                       |
|      54 | A Awe-Inspiring Drama of a Car And a Pastry Chef who must Chase a Crocodile in The First Manned Space Station                   |
|      55 | A Awe-Inspiring Story of a Feminist And a Cat who must Conquer a Dog in A Monastery                                             |
+---------+---------------------------------------------------------------------------------------------------------------------------------+
5 rows in set (0.00 sec)

root@localhost:sakila 04:45:06 &gt;explain select film_id,description from sakila.film order by title limit 50,5;
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra          |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+
|  1 | SIMPLE      | film  | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 1000 |   100.00 | Using filesort |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+
1 row in set, 1 warning (0.00 sec)

分析：
可以看出这个SQL使用了表扫描和文件排序的方式 ，这样如果表数据量很大会产生很大的IO问题

**优化步骤1、使用有索引的列或主键进行order by 操作**

root@localhost:sakila 04:57:53 &gt; select film_id, description from sakila.film order by film_id limit 50,5;       
+---------+---------------------------------------------------------------------------------------------------------------------------------+
| film_id | description                                                                                                                     |
+---------+---------------------------------------------------------------------------------------------------------------------------------+
|      51 | A Insightful Panorama of a Forensic Psychologist And a Mad Cow who must Build a Mad Scientist in The First Manned Space Station |
|      52 | A Thrilling Documentary of a Composer And a Monkey who must Find a Feminist in California                                       |
|      53 | A Epic Drama of a Madman And a Cat who must Face a A Shark in An Abandoned Amusement Park                                       |
|      54 | A Awe-Inspiring Drama of a Car And a Pastry Chef who must Chase a Crocodile in The First Manned Space Station                   |
|      55 | A Awe-Inspiring Story of a Feminist And a Cat who must Conquer a Dog in A Monastery                                             |
+---------+---------------------------------------------------------------------------------------------------------------------------------+
5 rows in set (0.00 sec)

root@localhost:sakila 04:48:55 &gt;explain select film_id, description from sakila.film order by film_id limit 50,5;
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------+
| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra |
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------+
|  1 | SIMPLE      | film  | NULL       | index | NULL          | PRIMARY | 2       | NULL |   55 |   100.00 | NULL  |
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------+
1 row in set, 1 warning (0.00 sec)

root@localhost:sakila 05:13:44 &gt;explain select film_id, description from sakila.film order by film_id limit 500,5;
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------+
| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra |
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------+
|  1 | SIMPLE      | film  | NULL       | index | NULL          | PRIMARY | 2       | NULL |  505 |   100.00 | NULL  |
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------+
1 row in set, 1 warning (0.00 sec)

分析：
因为innodb 引擎是使用主键的逻辑顺序进行排序的，经过优化发现已经不是全表扫描的方式了，但是如果参数的值增大，同样会造成扫描的行数远大于输出的结果

**优化步骤2、记录上次返回的主键，在下次查询时使用主键过滤。**
root@localhost:sakila 05:23:07 &gt;explain select film_id,description from sakila.film where film_id &gt; 500 and film_id &lt;=505 order by film_id limit 1,5;
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+
| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra       |
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+
|  1 | SIMPLE      | film  | NULL       | range | PRIMARY       | PRIMARY | 2       | NULL |    5 |   100.00 | Using where |
+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+
1 row in set, 1 warning (0.00 sec)

分析：
避免了数据量大时扫描过多的记录，这样操作有一个条件：要求主键是按顺序增长和连续的，如果有主键空缺某列和多列结果将不准确。

解决办法是附加一个index_id的列为自增和索引



</code></pre>

<h3 id="toc_19">3. 对于本章9个节点的学习，做好总结的学习笔记。</h3>

<p>安红雷、刘宏伟、王恩志可以给予运维环境方面的支持。<br/>
作业：<br/>
查看视频，针对以上9个学习点，形成笔记，转换PDF上传至Seafile。<br/>
注意事项：<br/>
完成学习后，修改计划完成日期为真实完成日期。</p>

            </div>
            <div>
                22222
                
                
            </div>
        </article>
    </div>
</div>
  <footer id="footer" class="yue">
    <div class="wrapper">
        <p>Designed and Written by <a href="https://twitter.com/Tisoga">Tisoga</a></p>
    </div>
</footer>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>
3333